<!DOCTYPE html>

<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Peter Radchenko's Homepage</title>
  
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="Tengyu Ma">
    <meta name="keywords" content="Tengyu Ma, Tengyu Ma Stanford, Tengyu Ma Machine Learning">
    <meta name="robots" content="index,follow">
    <meta name="description" content="Homepage of Tengyu Ma">
    <link href="./Peter Radchenko&#39;s Homepage_files/css" rel="stylesheet">
    <link rel="stylesheet" type="text/css" media="screen,print" href="./Peter Radchenko&#39;s Homepage_files/style.css">
  <link href="./Peter Radchenko&#39;s Homepage_files/bootstrap.min.css" rel="stylesheet" media="screen">
  <link rel="icon" type="image/png" href="https://ai.stanford.edu/~tengyuma/images/logos/princeton.png">
  <style>
  .button {
    background-color: #e7e7e7; color: black;/* Green */
    border: none;
    text-decoration: none;
    display: inline-block;
    margin: 4px 2px;
    cursor: pointer;
  }
</style>
<style>@media print {#ghostery-tracker-tally {display:none !important}}</style></head>


<body>
<div class="container">
<br>
<br>

<div class="row">
<div class="col-sm-4">
<br>
<img class="img-responsive" style="max-height:400px;" src="./Peter Radchenko&#39;s Homepage_files/square_3594.jpg">
</div>

<div class="col-sm-8">
<div class="clearfix visible-xs-block"></div>
<h1>Peter Radchekno<span style="font-family:STFangsong; font-size:20pt"></span></h1>





<p style="font-size: 14px">Professor of Business Analytics<br>
University of Sydney
<br>
<b>Office</b>: Gates 328 <br>
<b>Email</b>: <tt> first name.last name@sydney.edu.au</tt>. <br>
<a href="https://scholar.google.com/citations?user=DlnP7bEAAAAJ&hl=en" target="_blank">Google Scholar</a> 

</p></div>
</div>



<hr>
<h4>
  <a href="https://ai.stanford.edu/~tengyuma/#publications">Papers (by Topic) </a> /
  <a href="https://ai.stanford.edu/~tengyuma/#teaching">Teaching &amp; Service</a> /
  <a href="https://ai.stanford.edu/~tengyuma/#awards">Awards</a> 
</h4>
<hr>

<h3 id="bio">About</h3>
<p>
Hi! I am a Professor of Business Analytics at the University of Sydney. My research focusses on developing and analysing novel methodology for dealing with massive and complex modern data. 
</p>

<h3 id="alumni">Current Ph.D. students and post-docs</h3>
<ul>
    <li><a href="https://sites.google.com/view/colinwei" target="_blank">Colin Wei</a> </li>
    <li><a href="https://ananyakumar.wordpress.com/" target="_blank">Ananya Kumar</a> (co-advised with Percy Liang)</li>
    <li><a href="https://cynnjjs.github.io/" target="_blank">Yining Chen</a></li><a href="https://cynnjjs.github.io/" target="_blank">
    </a><li><a href="https://cynnjjs.github.io/" target="_blank"></a><a href="https://hongliny.github.io/" target="_blank">Honglin Yuan</a></li>
    <li><a href="https://ai.stanford.edu/~gwthomas/" target="_blank">Garrett Thomas</a> (co-advised with James Zou)</li>
    <li><a href="https://cs.stanford.edu/~eix/" target="_blank">Sang Michael Xie</a> (co-advised with Percy Liang)</li>
    <li><a href="https://cs.stanford.edu/~jhaochen/" target="_blank">Jeff Z. HaoChen</a></li>
    <li><a href="https://kfdong.github.io/" target="_blank">Kefan Dong</a></li>
    <li><a href="https://shibanisanturkar.com/" target="_blank">Shibani Santurkar</a> (postdoc, co-advised with Tatsu Hashimoto and Percy Liang)</li>
</ul>
<h3 id="students">Alumni</h3>
<ul>
    <li><a href="https://www.andrew.cmu.edu/user/yuanzhil/" target="_blank">Yuanzhi Li</a>
     (postdoc, now assistant prof. at CMU)</li>
</ul>

<div id="debug">
</div>

<h3 id="publications">Publications</h3>


<h4>
<button class="button" onclick="myFunction(&#39;manuscript&#39;)">
  Most Recent Works
  </button>
</h4>


<ul id="manuscript" style="display:none;">
<li><a href="https://arxiv.org/abs/2204.02683" target="_blank">Beyond Separability: Analyzing the Linear Transferability of Contrastive Representations to Related Subpopulations</a><br>Jeff Z. HaoChen, Colin Wei, Ananya Kumar, Tengyu Ma<br>Manuscript 2022. <a href="javascript:showb(&#39;uda-contrastive-theory&#39;,&#39;@article{haochen2022beyond,&lt;br&gt;  title={Beyond Separability: Analyzing the Linear Transferability of Contrastive Representations to Related Subpopulations},&lt;br&gt;  author={HaoChen, Jeff Z and Wei, Colin and Kumar, Ananya and Ma, Tengyu},&lt;br&gt;  journal={arXiv preprint arXiv:2204.02683},&lt;br&gt;  year={2022}&lt;br&gt;}&lt;br&gt;&#39;)">bib</a><div id="uda-contrastive-theory_bib"></div></li><br><li><a href="https://arxiv.org/abs/2204.00570" target="_blank">Connect, Not Collapse: Explaining Contrastive Learning for Unsupervised Domain Adaptation</a><br>Kendrick Shen, Robbie Jones, Ananya Kumar, Sang Michael Xie, Jeff Z. HaoChen, Tengyu Ma, Percy Liang<br>Manuscript 2022. <a href="javascript:showb(&#39;uda-contrastive&#39;,&#39;@article{shen2022connect,&lt;br&gt;  title={Connect, Not Collapse: Explaining Contrastive Learning for Unsupervised Domain Adaptation},&lt;br&gt;  author={Shen, Kendrick and Jones, Robbie and Kumar, Ananya and Xie, Sang Michael and HaoChen, Jeff Z and Ma, Tengyu and Liang, Percy},&lt;br&gt;  journal={arXiv preprint arXiv:2204.00570},&lt;br&gt;  year={2022}&lt;br&gt;}&lt;br&gt;&#39;)">bib</a><div id="uda-contrastive_bib"></div></li><br><li><a href="https://arxiv.org/abs/2111.02080" target="_blank">An Explanation of In-context Learning as Implicit Bayesian Inference</a><br>Sang Michael Xie, Aditi Raghunathan, Percy Liang, Tengyu Ma<br>ICLR 2022. <a href="javascript:showb(&#39;in-context-bayesian&#39;,&#39;@misc{xie2021explanation,&lt;br&gt;      title={An Explanation of In-context Learning as Implicit Bayesian Inference}, &lt;br&gt;      author={Sang Michael Xie and Aditi Raghunathan and Percy Liang and Tengyu Ma},&lt;br&gt;      year={2021},&lt;br&gt;      eprint={2111.02080},&lt;br&gt;      archivePrefix={arXiv},&lt;br&gt;      primaryClass={cs.CL}&lt;br&gt;}&#39;)">bib</a><div id="in-context-bayesian_bib"></div></li><br><li><a href="https://arxiv.org/abs/2110.05025" target="_blank">Self-supervised Learning is More Robust to Dataset Imbalance</a><br>Hong Liu, Jeff Z. HaoChen, Adrien Gaidon, Tengyu Ma<br>ICLR 2022, <i>spotlight</i>. <a href="javascript:showb(&#39;ssl-robustness&#39;,&#39;@misc{liu2021selfsupervised,&lt;br&gt;      title={Self-supervised Learning is More Robust to Dataset Imbalance}, &lt;br&gt;      author={Hong Liu and Jeff Z. HaoChen and Adrien Gaidon and Tengyu Ma},&lt;br&gt;      year={2021},&lt;br&gt;      eprint={2110.05025},&lt;br&gt;      archivePrefix={arXiv},&lt;br&gt;      primaryClass={cs.LG}&lt;br&gt;}&#39;)">bib</a> <a href="https://github.com/Liuhong99/Imbalanced-SSL" target="_blank">code</a><div id="ssl-robustness_bib"></div></li><br><li><a href="https://arxiv.org/abs/2202.10054" target="_blank">Fine-Tuning Distorts Pretrained Features and Underperforms Out-of-Distribution</a><br>Ananya Kumar, Aditi Raghunathan, Robbie Matthew Jones, Tengyu Ma, Percy Liang<br>ICLR 2022, <b>oral</b>. <a href="javascript:showb(&#39;lpfp&#39;,&#39;@article{kumar2022fine,&lt;br&gt;  title={Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution},&lt;br&gt;  author={Kumar, Ananya and Raghunathan, Aditi and Jones, Robbie and Ma, Tengyu and Liang, Percy},&lt;br&gt;  journal={arXiv preprint arXiv:2202.10054},&lt;br&gt;  year={2022}&lt;br&gt;}&#39;)">bib</a><div id="lpfp_bib"></div></li><br><li><a href="https://arxiv.org/abs/2111.03741" target="_blank">Sharp Bounds for Federated Averaging (Local SGD) and Continuous Perspective</a><br>Margalit Glasgow, Honglin Yuan, Tengyu Ma<br>AISTATS 2022. <a href="javascript:showb(&#39;fedavg-sharp&#39;,&#39;@misc{glasgow2021sharp,&lt;br&gt;      title={Sharp Bounds for Federated Averaging (Local SGD) and Continuous Perspective}, &lt;br&gt;      author={Margalit Glasgow and Honglin Yuan and Tengyu Ma},&lt;br&gt;      year={2021},&lt;br&gt;      eprint={2111.03741},&lt;br&gt;      archivePrefix={arXiv},&lt;br&gt;      primaryClass={cs.LG}&lt;br&gt;}&#39;)">bib</a><div id="fedavg-sharp_bib"></div></li><br><li><a href="https://ai.stanford.edu/~tengyuma/arxiv.org/abs/2111.11188" target="_blank">Plan Better Amid Conservatism: Offline Multi-Agent Reinforcement Learning with Actor Rectification</a><br>Ling Pan, Longbo Huang, Tengyu Ma, Huazhe Xu<br>Manuscript 2021. <a href="javascript:showb(&#39;omar&#39;,&#39;@misc{pan2021plan,&lt;br&gt;      title={Plan Better Amid Conservatism: Offline Multi-Agent Reinforcement Learning with Actor Rectification}, &lt;br&gt;      author={Ling Pan and Longbo Huang and Tengyu Ma and Huazhe Xu},&lt;br&gt;      year={2021},&lt;br&gt;      eprint={2111.11188},&lt;br&gt;      archivePrefix={arXiv},&lt;br&gt;      primaryClass={cs.LG}&lt;br&gt;}&#39;)">bib</a><div id="omar_bib"></div></li><br><li><a href="https://arxiv.org/abs/2107.13163" target="_blank">Statistically Meaningful Approximation: a Case Study on Approximating Turing Machines with Transformers</a><br>Colin Wei, Yining Chen, Tengyu Ma<br>Manuscript 2021. <a href="javascript:showb(&#39;statistcalapprox&#39;,&#39;@misc{wei2021statistically,&lt;br&gt;      title={Statistically Meaningful Approximation: a Case Study on Approximating Turing Machines with Transformers}, &lt;br&gt;      author={Colin Wei and Yining Chen and Tengyu Ma},&lt;br&gt;      year={2021},&lt;br&gt;      eprint={2107.13163},&lt;br&gt;      archivePrefix={arXiv},&lt;br&gt;      primaryClass={cs.LG}&lt;br&gt;}&#39;)">bib</a><div id="statistcalapprox_bib"></div></li><br></ul>


<h4>
<button class="button" onclick="myFunction(&#39;representation&#39;)">
  Pretraining, Representation Learning, and Out-of-Domain Generalization
  </button>
</h4>

<ul id="representation" style="display:none;">
<li><a href="http://arxiv.org/abs/2106.09226" target="_blank">Why Do Pretrained Language Models Help in Downstream Tasks? An Analysis of Head and Prompt Tuning</a><br>Colin Wei, Sang Michael Xie, Tengyu Ma<br>NeurIPS 2021, <i>spotlight</i>. <a href="javascript:showb(&#39;lm&#39;,&#39;@article{wei2021pretrained,&lt;br&gt;  title={Why do pretrained language models help in downstream tasks? an analysis of head and prompt tuning},&lt;br&gt;  author={Wei, Colin and Xie, Sang Michael and Ma, Tengyu},&lt;br&gt;  journal={Advances in Neural Information Processing Systems},&lt;br&gt;  volume={34},&lt;br&gt;  year={2021}&lt;br&gt;}&#39;)">bib</a> <a href="https://github.com/sangmichaelxie/pretraining_analysis" target="_blank">code</a><div id="lm_bib"></div></li><br><li><a href="https://arxiv.org/abs/2106.04156" target="_blank">Provable Guarantees for Self-Supervised Deep Learning with Spectral Contrastive Loss</a><br>Jeff Z. HaoChen, Colin Wei, Adrien Gaidon, Tengyu Ma<br>NeurIPS 2021, <b>oral</b>. <a href="javascript:showb(&#39;selfsup&#39;,&#39;@article{haochen2021provable,&lt;br&gt;  title={Provable guarantees for self-supervised deep learning with spectral contrastive loss},&lt;br&gt;  author={HaoChen, Jeff Z and Wei, Colin and Gaidon, Adrien and Ma, Tengyu},&lt;br&gt;  journal={Advances in Neural Information Processing Systems},&lt;br&gt;  volume={34},&lt;br&gt;  year={2021}&lt;br&gt;}&#39;)">bib</a> <a href="https://github.com/jhaochenz/spectral_contrastive_learning" target="_blank">code</a> <a href="https://ai.stanford.edu/~tengyuma/slides/selfsup.pptx" target="_blank">slides(pptx)</a> <a href="https://ai.stanford.edu/~tengyuma/slides/selfsup.pdf" target="_blank">slides(pdf)</a><div id="selfsup_bib"></div></li><br><li><a href="https://arxiv.org/abs/2010.03622" target="_blank">Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data</a><br>Colin Wei, Kendrick Shen, Yining Chen, Tengyu Ma<br>ICLR 2021, <b>oral</b>. <a href="javascript:showb(&#39;Self-training-expansion&#39;,&#39;@inproceedings{wei2020theoretical,&lt;br&gt;  title={Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data},&lt;br&gt;  author={Wei, Colin and Shen, Kendrick and Chen, Yining and Ma, Tengyu},&lt;br&gt;  booktitle={International Conference on Learning Representations},&lt;br&gt;  year={2020}&lt;br&gt;}&#39;)">bib</a> <a href="https://ai.stanford.edu/~tengyuma/slides/self_training.pptx" target="_blank">slides(pptx)</a> <a href="https://ai.stanford.edu/~tengyuma/slides/self_training.pdf" target="_blank">slides(pdf)</a><div id="Self-training-expansion_bib"></div></li><br><li><a href="https://arxiv.org/abs/2011.01418" target="_blank">Meta-learning Transferable Representations with a Single Target Domain</a><br>Hong Liu, Jeff Z. HaoChen, Colin Wei, Tengyu Ma<br>Manuscript 2020. <a href="javascript:showb(&#39;merlin&#39;,&#39;@misc{liu2020metalearning,&lt;br&gt;      title={Meta-learning Transferable Representations with a Single Target Domain}, &lt;br&gt;      author={Hong Liu and Jeff Z. HaoChen and Colin Wei and Tengyu Ma},&lt;br&gt;      year={2020},&lt;br&gt;      eprint={2011.01418},&lt;br&gt;      archivePrefix={arXiv},&lt;br&gt;      primaryClass={cs.LG}&lt;br&gt;}&#39;)">bib</a><div id="merlin_bib"></div></li><br><li><a href="https://arxiv.org/abs/2012.04550" target="_blank">In-N-Out: Pre-Training and Self-Training using Auxiliary Information for Out-of-Distribution Robustness</a><br>Sang Michael Xie*, Ananya Kumar*, Robbie Jones*, Fereshte Khani, Tengyu Ma, Percy Liang<br>ICLR 2021. <a href="javascript:showb(&#39;in-and-out&#39;,&#39;@inproceedings{xie2020n,&lt;br&gt;  title={In-N-Out: Pre-Training and Self-Training using Auxiliary Information for Out-of-Distribution Robustness},&lt;br&gt;  author={Xie, Sang Michael and Kumar, Ananya and Jones, Robbie and Khani, Fereshte and Ma, Tengyu and Liang, Percy},&lt;br&gt;  booktitle={International Conference on Learning Representations},&lt;br&gt;  year={2020}&lt;br&gt;}&#39;)">bib</a> <a href="https://worksheets.codalab.org/worksheets/0x2613c72d4f3f4fbb94e0a32c17ce5fb0" target="_blank">code</a><div id="in-and-out_bib"></div></li><br><li><a href="https://arxiv.org/abs/2006.16205" target="_blank">Composed Fine-Tuning: Freezing Pre-Trained Denoising Autoencoders for Improved Generalization</a><br>Sang Michael Xie, Tengyu Ma, Percy Liang<br>ICML 2021. <a href="javascript:showb(&#39;unlabeledoutput&#39;,&#39;@inproceedings{xie2021composed,&lt;br&gt;  title={Composed Fine-Tuning: Freezing Pre-Trained Denoising Autoencoders for Improved Generalization},&lt;br&gt;  author={Xie, Sang Michael and Ma, Tengyu and Liang, Percy},&lt;br&gt;  booktitle={International Conference on Machine Learning},&lt;br&gt;  pages={11424--11435},&lt;br&gt;  year={2021},&lt;br&gt;  organization={PMLR}&lt;br&gt;}&#39;)">bib</a> <a href="https://github.com/p-lambda/composed_finetuning" target="_blank">code</a><div id="unlabeledoutput_bib"></div></li><br><li><a href="https://arxiv.org/abs/2006.15766" target="_blank">Heteroskedastic and Imbalanced Deep Learning with Adaptive Regularization</a><br>Kaidi Cao, Yining Chen, Junwei Lu, Nikos Arechiga, Adrien Gaidon, Tengyu Ma<br>ICLR 2021. <a href="javascript:showb(&#39;Heteroskedastic&#39;,&#39;@inproceedings{cao2020heteroskedastic,&lt;br&gt;  title={Heteroskedastic and Imbalanced Deep Learning with Adaptive Regularization},&lt;br&gt;  author={Cao, Kaidi and Chen, Yining and Lu, Junwei and Arechiga, Nikos and Gaidon, Adrien and Ma, Tengyu},&lt;br&gt;  booktitle={International Conference on Learning Representations},&lt;br&gt;  year={2020}&lt;br&gt;}&#39;)">bib</a> <a href="https://github.com/kaidic/HAR" target="_blank">code</a><div id="Heteroskedastic_bib"></div></li><br><li><a href="https://arxiv.org/abs/2006.10032" target="_blank">Self-training Avoids Using Spurious Features Under Domain Shift</a><br>Yining Chen*, Colin Wei*, Ananya Kumar, Tengyu Ma<br>NeurIPS 2020. <a href="javascript:showb(&#39;Self-Training&#39;,&#39;@article{chen2020self, &lt;br&gt; title={Self-training Avoids Using Spurious Features Under Domain Shift}, &lt;br&gt; author={Chen, Yining and Wei, Colin and Kumar, Ananya and Ma, Tengyu}, &lt;br&gt; journal={arXiv preprint arXiv:2006.10032}, &lt;br&gt; year={2020} &lt;br&gt; }&#39;)">bib</a> <a href="https://github.com/cynnjjs/spurious_feature_NeuRIPS" target="_blank">code</a><div id="Self-Training_bib"></div></li><br><li><a href="https://arxiv.org/abs/2002.11361" target="_blank">Understanding Self-Training for Gradual Domain Adaptation</a><br>Ananya Kumar, Tengyu Ma, Percy Liang<br>ICML 2020. <a href="javascript:showb(&#39;gradual&#39;,&#39;@inproceedings{kumar2020gradual, &lt;br&gt; title={Understanding Self-Training for Gradual Domain Adaptation}, &lt;br&gt; author={Kumar, Ananya and Ma, Tengyu and Liang, Percy},&lt;br&gt; booktitle={International Conference on Machine Learning (ICML)}, year={2020}, &lt;br&gt; organization={PMLR} &lt;br&gt; }&#39;)">bib</a> <a href="https://github.com/p-lambda/gradual_domain_adaptation" target="_blank">code</a><div id="gradual_bib"></div></li><br><li><a href="https://arxiv.org/abs/1906.07413" target="_blank">Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss</a><br>Kaidi Cao, Colin Wei, Adrien Gaidon, Nikos Arechiga, Tengyu Ma<br>NeurIPS 2019. <a href="javascript:showb(&#39;imb&#39;,&#39;@inproceedings{cao2019learning,  &lt;br&gt; title={Learning imbalanced datasets with label-distribution-aware margin loss},  &lt;br&gt; author={Cao, Kaidi and Wei, Colin and Gaidon, Adrien and Arechiga, Nikos and Ma, Tengyu},  &lt;br&gt; booktitle={Advances in Neural Information Processing Systems},  &lt;br&gt; pages={1567--1578},  &lt;br&gt; year={2019} &lt;br&gt; }&#39;)">bib</a> <a href="https://github.com/kaidic/LDAM-DRW" target="_blank">code</a><div id="imb_bib"></div></li><br><li><a href="http://arxiv.org/abs/1601.03764" target="_blank">Linear Algebraic Structure of Word Senses, with Applications to Polysemy</a><br>Sanjeev Arora, Yuanzhi Li, Yingyu Liang, Tengyu Ma, and Andrej Risteski<br>TACL 2019. <a href="javascript:showb(&#39;polysemy&#39;,&#39;@article{arora2018linear,&lt;br&gt;  title={Linear algebraic structure of word senses, with applications to polysemy},&lt;br&gt;  author={Arora, Sanjeev and Li, Yuanzhi and Liang, Yingyu and Ma, Tengyu and Risteski, Andrej},&lt;br&gt;  journal={Transactions of the Association for Computational Linguistics},&lt;br&gt;  volume={6},&lt;br&gt;  pages={483--495},&lt;br&gt;  year={2018},&lt;br&gt;  publisher={MIT Press}&lt;br&gt;}&#39;)">bib</a><div id="polysemy_bib"></div></li><br><li><a href="https://arxiv.org/abs/1805.05388" target="_blank">A La Carte Embedding: Cheap but Effective Induction of Semantic Feature Vectors</a><br>Mikhail Khodak, Nikunj Saunshi, Yingyu Liang, Tengyu Ma, Brandon Stewart, Sanjeev Arora<br>ACL 2018. <a href="javascript:showb(&#39;alacarte&#39;,&#39;@inproceedings{khodak2018carte,&lt;br&gt;  title={A La Carte Embedding: Cheap but Effective Induction of Semantic Feature Vectors},&lt;br&gt;  author={Khodak, Mikhail and Saunshi, Nikunj and Liang, Yingyu and Ma, Tengyu and Stewart, Brandon M and Arora, Sanjeev},&lt;br&gt;  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},&lt;br&gt;  pages={12--22},&lt;br&gt;  year={2018}&lt;br&gt;}&#39;)">bib</a><div id="alacarte_bib"></div></li><br><li><a href="http://arxiv.org/abs/1502.03520" target="_blank">RAND-WALK: A Latent Variable Model Approach to Word Embeddings</a><br>Sanjeev Arora, Yuanzhi Li, Yingyu Liang, Tengyu Ma, and Andrej Risteski<br>TACL, 4:385-399, 2016. <a href="javascript:showb(&#39;randomwalk&#39;,&#39;@article{arora2015latent,&lt;br&gt;  title={A latent variable model approach to PMI-based word embeddings},&lt;br&gt;  author={Arora, Sanjeev and Li, Yuanzhi and Liang, Yingyu and Ma, Tengyu and Risteski, Andrej},&lt;br&gt;  journal={Transactions of the Association for Computational Linguistics},&lt;br&gt;  year={2016}&lt;br&gt;}&#39;)">bib</a><div id="randomwalk_bib"></div></li><br><li><a href="https://openreview.net/forum?id=SyK00v5xx" target="_blank">A Simple but Tough-to-Beat Baseline for Sentence Embeddings</a><br>Sanjeev Arora, Yingyu Liang, and Tengyu Ma<br>ICLR 2017. <a href="javascript:showb(&#39;sentence&#39;,&#39;@article{arora2016simple,&lt;br&gt;  title={A simple but tough-to-beat baseline for sentence embeddings},&lt;br&gt;  author={Arora, Sanjeev and Liang, Yingyu and Ma, Tengyu},&lt;br&gt;  year={2016},&lt;br&gt;  journal={International Conference on Learning Representations},&lt;br&gt;}&#39;)">bib</a><div id="sentence_bib"></div></li><br></ul>



<h4>
<button class="button" onclick="myFunction(&#39;generalization&#39;)">
  Generalization Theory (Implicit and Explicit Regularization)
  </button>
</h4>

<ul id="generalization" style="display:none;">
<li><a href="https://arxiv.org/abs/2106.06530" target="_blank">Label Noise SGD Provably Prefers Flat Global Minimizers</a><br>Alex Damian, Tengyu Ma, Jason Lee<br>NeurIPS 2021. <a href="javascript:showb(&#39;labelnoise-global&#39;,&#39;@article{damian2021label,&lt;br&gt;  title={Label noise sgd provably prefers flat global minimizers},&lt;br&gt;  author={Damian, Alex and Ma, Tengyu and Lee, Jason D},&lt;br&gt;  journal={Advances in Neural Information Processing Systems},&lt;br&gt;  volume={34},&lt;br&gt;  year={2021}&lt;br&gt;}&#39;)">bib</a><div id="labelnoise-global_bib"></div></li><br><li><a href="https://arxiv.org/abs/2006.08680" target="_blank">Shape Matters: Understanding the Implicit Bias of the Noise Covariance</a><br>Jeff Z. HaoChen, Colin Wei, Jason D. Lee, Tengyu Ma<br>COLT 2021. <a href="javascript:showb(&#39;shape&#39;,&#39;@inproceedings{haochen2021shape,&lt;br&gt;  title={Shape matters: Understanding the implicit bias of the noise covariance},&lt;br&gt;  author={HaoChen, Jeff Z and Wei, Colin and Lee, Jason and Ma, Tengyu},&lt;br&gt;  booktitle={Conference on Learning Theory},&lt;br&gt;  pages={2315--2357},&lt;br&gt;  year={2021},&lt;br&gt;  organization={PMLR}&lt;br&gt;}&#39;)">bib</a> <a href="https://github.com/jhaochenz/noise-implicit-bias" target="_blank">code</a> <a href="https://ai.stanford.edu/~tengyuma/slides/shape_matters.pptx" target="_blank">slides(pptx)</a> <a href="https://ai.stanford.edu/~tengyuma/slides/shape_matters.pdf" target="_blank">slides(pdf)</a><div id="shape_bib"></div></li><br><li><a href="https://arxiv.org/abs/2003.01897" target="_blank">Optimal Regularization Can Mitigate Double Descent</a><br>Preetum Nakkiran, Prayaag Venkat, Sham Kakade, Tengyu Ma<br>ICLR 2021. <a href="javascript:showb(&#39;dd&#39;,&#39;@inproceedings{nakkiran2020optimal,&lt;br&gt;  title={Optimal Regularization can Mitigate Double Descent},&lt;br&gt;  author={Nakkiran, Preetum and Venkat, Prayaag and Kakade, Sham M and Ma, Tengyu},&lt;br&gt;  booktitle={International Conference on Learning Representations},&lt;br&gt;  year={2020}&lt;br&gt;}&#39;)">bib</a><div id="dd_bib"></div></li><br><li><a href="https://arxiv.org/abs/2002.12915" target="_blank">The Implicit and Explicit Regularization Effects of Dropout</a><br>Colin Wei, Sham Kakade, Tengyu Ma<br>ICML 2020. <a href="javascript:showb(&#39;dropout&#39;,&#39;@inproceedings{wei2020implicit, &lt;br&gt; title={The Implicit and Explicit Regularization Effects of Dropout}, &lt;br&gt; author={Wei, Colin and Kakade, Sham and Ma, Tengyu}, &lt;br&gt; booktitle={International Conference on Machine Learning}, &lt;br&gt; year={2020} &lt;br&gt;}&#39;)">bib</a> <a href="https://github.com/cwein3/dropout-analytical" target="_blank">code</a><div id="dropout_bib"></div></li><br><li><a href="https://arxiv.org/abs/1910.04284" target="_blank">Improved Sample Complexities for Deep Networks and Robust Classification via an All-Layer Margin</a><br>Colin Wei, Tengyu Ma<br>ICLR 2020. <a href="javascript:showb(&#39;all-layer&#39;,&#39;@inproceedings{wei2019improved, &lt;br&gt; title={Improved sample complexities for deep neural networks and robust classification via an all-layer margin}, &lt;br&gt; author={Wei, Colin and Ma, Tengyu}, &lt;br&gt; booktitle={International Conference on Learning Representations}, &lt;br&gt; year={2019} &lt;br&gt; }&#39;)">bib</a> <a href="https://github.com/cwein3/all-layer-margin-opt" target="_blank">code</a><div id="all-layer_bib"></div></li><br><li><a href="https://arxiv.org/abs/1907.04595" target="_blank">Towards Explaining the Regularization Effect of Initial Large Learning Rate in Training Neural Networks</a><br>Yuanzhi Li*, Colin Wei*, Tengyu Ma<br>NeurIPS 2019. <a href="javascript:showb(&#39;largeLR&#39;,&#39;@inproceedings{li2019towards, &lt;br&gt; title={Towards explaining the regularization effect of initial large learning rate in training neural networks}, &lt;br&gt; author={Li, Yuanzhi and Wei, Colin and Ma, Tengyu}, &lt;br&gt; booktitle={Advances in Neural Information Processing Systems}, &lt;br&gt; pages={11674--11685}, &lt;br&gt; year={2019} &lt;br&gt; }&#39;)">bib</a> <a href="https://github.com/cwein3/large-lr-code" target="_blank">code</a><div id="largeLR_bib"></div></li><br><li><a href="https://arxiv.org/abs/1810.05369" target="_blank">Regularization Matters: Generalization and Optimization of Neural Nets v.s. their Induced Kernel</a><br>Colin Wei, Jason D. Lee, Qiang Liu, Tengyu Ma<br>NeurIPS 2019, <i>spotlight</i>. <a href="javascript:showb(&#39;regmatters&#39;,&#39;@inproceedings{wei2019regularization, &lt;br&gt; title={Regularization matters: Generalization and optimization of neural nets vs their induced kernel}, &lt;br&gt; author={Wei, Colin and Lee, Jason D and Liu, Qiang and Ma, Tengyu}, &lt;br&gt; booktitle={Advances in Neural Information Processing Systems}, &lt;br&gt; pages={9712--9724}, &lt;br&gt; year={2019} &lt;br&gt; }&#39;)">bib</a><div id="regmatters_bib"></div></li><br><li><a href="https://arxiv.org/abs/1905.03684" target="_blank">Data-dependent Sample Complexity of Deep Neural Networks via Lipschitz Augmentation</a><br>Colin Wei,  Tengyu Ma<br>NeurIPS 2019 (<i>spotlight</i>). <a href="javascript:showb(&#39;Lipschitz_aug&#39;,&#39;@inproceedings{wei2019data, &lt;br&gt; title={Data-dependent sample complexity of deep neural networks via lipschitz augmentation}, &lt;br&gt; author={Wei, Colin and Ma, Tengyu}, &lt;br&gt; booktitle={Advances in Neural Information Processing Systems}, &lt;br&gt; pages={9725--9736}, &lt;br&gt; year={2019} &lt;br&gt; }&#39;)">bib</a> <a href="https://github.com/cwein3/jacobian-reg" target="_blank">code</a><div id="Lipschitz_aug_bib"></div></li><br><li><a href="https://arxiv.org/abs/1712.09203" target="_blank">Algorithmic Regularization in Over-parameterized Matrix Sensing and Neural Networks with Quadratic Activations</a><br>Yuanzhi Li, Tengyu Ma, and Hongyang Zhang<br>COLT 2018 (<b>Best Paper Award</b>). <a href="javascript:showb(&#39;smallint&#39;,&#39;@inproceedings{li2018algorithmic, &lt;br&gt; title={Algorithmic regularization in over-parameterized matrix sensing and neural networks with quadratic activations}, &lt;br&gt; author={Li, Yuanzhi and Ma, Tengyu and Zhang, Hongyang},&lt;br&gt; booktitle={Conference On Learning Theory}, pages={2--47}, &lt;br&gt; year={2018}, &lt;br&gt; organization={PMLR} &lt;br&gt; }&#39;)">bib</a><div id="smallint_bib"></div></li><br></ul>






<h4>
  <button class="button" onclick="myFunction(&#39;RL&#39;)">
  Reinforcement Learning
  </button>
</h4>

<ul id="RL" style="display:none;">
<li><a href="https://arxiv.org/abs/2112.04716" target="_blank">DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization</a><br>Aviral Kumar, Rishabh Agarwal, Tengyu Ma, Aaron Courville, George Tucker, Sergey Levine<br>ICLR 2022, <i>spotlight</i>. <a href="javascript:showb(&#39;dr3&#39;,&#39;@article{kumar2021dr3,&lt;br&gt;  title={DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization},&lt;br&gt;  author={Kumar, Aviral and Agarwal, Rishabh and Ma, Tengyu and Courville, Aaron and Tucker, George and Levine, Sergey},&lt;br&gt;  journal={arXiv preprint arXiv:2112.04716},&lt;br&gt;  year={2021}&lt;br&gt;}&#39;)">bib</a><div id="dr3_bib"></div></li><br><li><a href="https://arxiv.org/abs/2108.01846" target="_blank">Learning Barrier Certificates: Towards Safe Reinforcement Learning with Zero Training-time Violations</a><br>Yuping Luo, Tengyu Ma<br>NeurIPS 2021. <a href="javascript:showb(&#39;barrercertificate&#39;,&#39;@article{luo2021learning,&lt;br&gt;  title={Learning Barrier Certificates: Towards Safe Reinforcement Learning with Zero Training-time Violations},&lt;br&gt;  author={Luo, Yuping and Ma, Tengyu},&lt;br&gt;  journal={Advances in Neural Information Processing Systems},&lt;br&gt;  volume={34},&lt;br&gt;  year={2021}&lt;br&gt;}&#39;)">bib</a> <a href="https://github.com/roosephu/crabs" target="_blank">code</a><div id="barrercertificate_bib"></div></li><br><li><a href="https://arxiv.org/abs/2202.07789" target="_blank">Safe Reinforcement Learning by Imagining the Near Future</a><br>Garrett Thomas, Yuping Luo, Tengyu Ma<br>NeurIPS 2021. <a href="javascript:showb(&#39;smbpo&#39;,&#39;@article{thomas2021safe,&lt;br&gt;  title={Safe Reinforcement Learning by Imagining the Near Future},&lt;br&gt;  author={Thomas, Garrett and Luo, Yuping and Ma, Tengyu},&lt;br&gt;  journal={Advances in Neural Information Processing Systems},&lt;br&gt;  volume={34},&lt;br&gt;  year={2021}&lt;br&gt;}&#39;)">bib</a> <a href="https://github.com/gwthomas/Safe-MBPO" target="_blank">code</a><div id="smbpo_bib"></div></li><br><li><a href="https://arxiv.org/abs/2102.04692" target="_blank">Fine-Grained Gap-Dependent Bounds for Tabular MDPs via Adaptive Multi-Step Bootstrap</a><br>Haike Xu, Tengyu Ma, Simon S. Du<br>COLT 2021. <a href="javascript:showb(&#39;gap&#39;,&#39;@inproceedings{xu2021fine,&lt;br&gt;  title={Fine-grained gap-dependent bounds for tabular mdps via adaptive multi-step bootstrap},&lt;br&gt;  author={Xu, Haike and Ma, Tengyu and Du, Simon},&lt;br&gt;  booktitle={Conference on Learning Theory},&lt;br&gt;  pages={4438--4472},&lt;br&gt;  year={2021},&lt;br&gt;  organization={PMLR}&lt;br&gt;}&#39;)">bib</a><div id="gap_bib"></div></li><br><li><a href="https://arxiv.org/abs/2102.04168" target="_blank">Provable Model-based Nonlinear Bandit and Reinforcement Learning: Shelve Optimism, Embrace Virtual Curvature</a><br>Kefan Dong, Jiaqi Yang, Tengyu Ma<br>NeurIPS 2021. <a href="javascript:showb(&#39;viol&#39;,&#39;@article{dong2021provable,&lt;br&gt;  title={Provable model-based nonlinear bandit and reinforcement learning: Shelve optimism, embrace virtual curvature},&lt;br&gt;  author={Dong, Kefan and Yang, Jiaqi and Ma, Tengyu},&lt;br&gt;  journal={Advances in Neural Information Processing Systems},&lt;br&gt;  volume={34},&lt;br&gt;  year={2021}&lt;br&gt;}&#39;)">bib</a> <a href="https://ai.stanford.edu/~tengyuma/slides/viol.pptx" target="_blank">slides(pptx)</a> <a href="https://ai.stanford.edu/~tengyuma/slides/viol.pdf" target="_blank">slides(pdf)</a><div id="viol_bib"></div></li><br><li><a href="https://arxiv.org/abs/2005.13239" target="_blank">MOPO: Model-based Offline Policy Optimization</a><br>Tianhe Yu*, Garrett Thomas*, Lantao Yu, Stefano Ermon, James Zou, Sergey Levine, Chelsea Finn*, Tengyu Ma*<br>NeurIPS 2020. <a href="javascript:showb(&#39;mopo&#39;,&#39;@article{yu2020mopo,&lt;br&gt;  title={Mopo: Model-based offline policy optimization},&lt;br&gt;  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James Y and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},&lt;br&gt;  journal={Advances in Neural Information Processing Systems},&lt;br&gt;  volume={33},&lt;br&gt;  pages={14129--14142},&lt;br&gt;  year={2020}&lt;br&gt;}&#39;)">bib</a> <a href="https://github.com/tianheyu927/mopo" target="_blank">code</a><div id="mopo_bib"></div></li><br><li><a href="https://arxiv.org/abs/2006.08875" target="_blank">Model-based Adversarial Meta-Reinforcement Learning</a><br>Zichuan Lin, Garrett Thomas, Guangwen Yang, Tengyu Ma<br>NeurIPS 2020. <a href="javascript:showb(&#39;admrl&#39;,&#39;@article{lin2020model,&lt;br&gt;  title={Model-based adversarial meta-reinforcement learning},&lt;br&gt;  author={Lin, Zichuan and Thomas, Garrett and Yang, Guangwen and Ma, Tengyu},&lt;br&gt;  journal={Advances in Neural Information Processing Systems},&lt;br&gt;  volume={33},&lt;br&gt;  pages={10161--10173},&lt;br&gt;  year={2020}&lt;br&gt;}&#39;)">bib</a> <a href="https://github.com/LinZichuan/AdMRL" target="_blank">code</a><div id="admrl_bib"></div></li><br><li><a href="https://arxiv.org/abs/2006.14481" target="_blank">Active Online Learning with Hidden Shifting Domains</a><br>Yining Chen, Haipeng Luo, Tengyu Ma, Chicheng Zhang<br>AISTATS 2020. <a href="javascript:showb(&#39;qufur&#39;,&#39;@article{chen2020active, &lt;br&gt; title={Active Online Domain Adaptation}, &lt;br&gt; author={Chen, Yining and Luo, Haipeng and Ma, Tengyu and Zhang, Chicheng},&lt;br&gt; journal={arXiv preprint arXiv:2006.14481}, &lt;br&gt; year={2020} &lt;br&gt;}&#39;)">bib</a> <a href="https://github.com/cynnjjs/online_active_AISTATS" target="_blank">code</a><div id="qufur_bib"></div></li><br><li><a href="https://arxiv.org/abs/1910.05927" target="_blank">On the Expressivity of Neural Networks for Deep Reinforcement Learning</a><br>Kefan Dong*, Yuping Luo*, Tengyu Ma<br>ICML 2020. <a href="javascript:showb(&#39;ExpressivityRL&#39;,&#39;@inproceedings{dong2020expressivity, &lt;br&gt; title={On the Expressivity of Neural Networks for Deep Reinforcement Learning}, &lt;br&gt; author={Dong, Kefan and Luo, Yuping and Yu, Tianhe and Finn, Chelsea and Ma, Tengyu}, &lt;br&gt; booktitle={International Conference on Machine Learning}, &lt;br&gt; year={2020}&lt;br&gt;}&#39;)">bib</a> <a href="https://github.com/roosephu/boots" target="_blank">code</a><div id="ExpressivityRL_bib"></div></li><br><li><a href="https://arxiv.org/abs/1907.05634" target="_blank">Learning Self-Correctable Policies and Value Functions from Demonstrations with Negative Sampling</a><br>Yuping Luo, Huazhe Xu, Tengyu Ma<br>ICLR 2020. <a href="javascript:showb(&#39;vins&#39;,&#39;@inproceedings{&lt;br&gt;  luo2020learning,&lt;br&gt;  title={Learning Self-Correctable Policies and Value Functions from Demonstrations with Negative Sampling},&lt;br&gt;  author={Yuping Luo and Huazhe Xu and Tengyu Ma},&lt;br&gt;  booktitle={International Conference on Learning Representations},&lt;br&gt;  year={2020},&lt;br&gt;}&#39;)">bib</a><div id="vins_bib"></div></li><br><li><a href="https://arxiv.org/abs/1905.046544" target="_blank">On the Performance of Thompson Sampling on Logistic Bandits</a><br>Shi Dong, Tengyu Ma, and Benjamin Van Roy<br>COLT 2019. <a href="javascript:showb(&#39;tslogistics&#39;,&#39;@inproceedings{dong2019performance,&lt;br&gt; title={On the Performance of Thompson Sampling on Logistic Bandits},&lt;br&gt; author={Dong, Shi and Ma, Tengyu and Van Roy, Benjamin},&lt;br&gt; booktitle={Conference on Learning Theory},&lt;br&gt; pages={1158--1160},&lt;br&gt; year={2019}&lt;br&gt;}&#39;)">bib</a><div id="tslogistics_bib"></div></li><br><li><a href="https://arxiv.org/abs/1807.03858" target="_blank">Algorithmic Framework for Model-based Reinforcement Learning with Theoretical Guarantees</a><br>Yuping Luo*, Huazhe Xu*, Yuanzhi Li, Yuandong Tian, Trevor Darrell, Tengyu Ma<br>ICLR 2019. <a href="javascript:showb(&#39;slbo&#39;,&#39;@inproceedings{&lt;br&gt;  luo2019algorithmic,&lt;br&gt;  title={Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees},&lt;br&gt;  author={Yuping Luo and Huazhe Xu and Yuanzhi Li and Yuandong Tian and Trevor Darrell and Tengyu Ma},&lt;br&gt;  booktitle={International Conference on Learning Representations},&lt;br&gt;  year={2019},&lt;br&gt;  url={https://openreview.net/forum?id=BJe1E2R5KX},&lt;br&gt;}&#39;)">bib</a><div id="slbo_bib"></div></li><br><li><a href="http://jmlr.org/proceedings/papers/v37/garberb15-supp.pdf" target="_blank">Online Learning of Eigenvectors</a><br>Dan Garber and Elad Hazan and Tengyu Ma<br>ICML 2015. <a href="javascript:showb(&#39;eigen&#39;,&#39;@inproceedings{garber2015online,&lt;br&gt; title={Online Learning of Eigenvectors.},&lt;br&gt; author={Garber, Dan and Hazan, Elad and Ma, Tengyu}, &lt;br&gt;booktitle={ICML}, &lt;br&gt; pages={560--568}, &lt;br&gt;year={2015}&lt;br&gt;}&#39;)">bib</a><div id="eigen_bib"></div></li><br></ul>

<h4>
  <button class="button" onclick="myFunction(&#39;opt&#39;)">
  Nonconvex Optimization 
  </button>
</h4>



<ul id="opt" style="display:none;">
<li><a href="https://arxiv.org/abs/2010.11356" target="_blank">Beyond Lazy Training for Over-parameterized Tensor Decomposition</a><br>Xiang Wang, Chenwei Wu, Jason D. Lee, Tengyu Ma, Rong Ge<br>NeurIPS 2020. <a href="javascript:showb(&#39;beyondlazytensor&#39;,&#39;@article{wang2020beyond,&lt;br&gt;  title={Beyond lazy training for over-parameterized tensor decomposition},&lt;br&gt;  author={Wang, Xiang and Wu, Chenwei and Lee, Jason D and Ma, Tengyu and Ge, Rong},&lt;br&gt;  journal={Advances in Neural Information Processing Systems},&lt;br&gt;  volume={33},&lt;br&gt;  pages={21934--21944},&lt;br&gt;  year={2020}&lt;br&gt;}&#39;)">bib</a><div id="beyondlazytensor_bib"></div></li><br><li><a href="http://arxiv.org/abs/2103.13462" target="_blank">Why Do Local Methods Solve Nonconvex Problems?</a><br>Tengyu Ma<br> Chapter 21 of <a href="https://www.cambridge.org/core/books/beyond-the-worstcase-analysis-of-algorithms/8A8128BBF7FC2857471E9CA52E69AC21" target="_blank">Beyond the Worst-Case Analysis of Algorithms</a>. <a href="javascript:showb(&#39;nonconvexsurvey&#39;,&#39;@misc{ma2021local,&lt;br&gt;      title={Why Do Local Methods Solve Nonconvex Problems?}, &lt;br&gt;      author={Tengyu Ma},&lt;br&gt;      year={2021},&lt;br&gt;      eprint={2103.13462},&lt;br&gt;      archivePrefix={arXiv},&lt;br&gt;      primaryClass={cs.LG}&lt;br&gt;}&#39;)">bib</a><div id="nonconvexsurvey_bib"></div></li><br><li><a href="https://arxiv.org/abs/2007.04596" target="_blank">Learning Over-Parametrized Two-Layer ReLU Neural Networks beyond NTK</a><br>Yuanzhi Li, Tengyu Ma, Hongyang R. Zhang<br>COLT 2020. <a href="javascript:showb(&#39;Two-Layerrelu&#39;,&#39;@inproceedings{li2020learning,&lt;br&gt;	title={Learning over-parametrized two-layer neural networks beyond ntk},&lt;br&gt;	author={Li, Yuanzhi and Ma, Tengyu and Zhang, Hongyang R},&lt;br&gt;	booktitle={Conference on Learning Theory},&lt;br&gt;	pages={2613--2682},&lt;br&gt;	year={2020},&lt;br&gt;	organization={PMLR}&lt;br&gt;}&#39;)">bib</a><div id="Two-Layerrelu_bib"></div></li><br><li><a href="https://arxiv.org/abs/1901.09321" target="_blank">Fixup Initialization: Residual Learning Without Normalization</a><br>Hongyi Zhang, Yann N. Dauphin, Tengyu Ma<br>NeurIPS 2019. <a href="javascript:showb(&#39;fixup&#39;,&#39;@inproceedings{zhang2018fixup,&lt;br&gt;  title={Fixup Initialization: Residual Learning Without Normalization},&lt;br&gt;  author={Zhang, Hongyi and Dauphin, Yann N and Ma, Tengyu},&lt;br&gt;  booktitle={International Conference on Learning Representations},&lt;br&gt;  year={2018}&lt;br&gt;}&#39;)">bib</a><div id="fixup_bib"></div></li><br><li><a href="https://arxiv.org/abs/1609.05191" target="_blank">Gradient Descent Learns Linear Dynamical Systems</a><br>Moritz Hardt, Tengyu Ma, and Benjamin Recht<br>JMLR, 19(29):1−44, 2018. <a href="javascript:showb(&#39;lineardynamicalsystems&#39;,&#39;@article{hardt2018gradient,&lt;br&gt;  title={Gradient descent learns linear dynamical systems},&lt;br&gt;  author={Hardt, Moritz and Ma, Tengyu and Recht, Benjamin},&lt;br&gt;  journal={The Journal of Machine Learning Research},&lt;br&gt;  volume={19},&lt;br&gt;  number={1},&lt;br&gt;  pages={1025--1068},&lt;br&gt;  year={2018},&lt;br&gt;  publisher={JMLR. org}&lt;br&gt;}&#39;)">bib</a><div id="lineardynamicalsystems_bib"></div></li><br><li><a href="https://arxiv.org/abs/1711.00501" target="_blank">Learning One-hidden-layer Neural Networks with Landscape Design</a><br>Rong Ge, Jason D. Lee, and Tengyu Ma<br>ICLR 2018. <a href="javascript:showb(&#39;Landscape&#39;,&#39;@inproceedings{ge2018learning,&lt;br&gt;  title={Learning One-hidden-layer Neural Networks with Landscape Design},&lt;br&gt;  author={Ge, Rong and Lee, Jason D and Ma, Tengyu},&lt;br&gt;  booktitle={International Conference on Learning Representations},&lt;br&gt;  year={2018}&lt;br&gt;}&#39;)">bib</a><div id="Landscape_bib"></div></li><br><li><a href="https://arxiv.org/abs/1706.05598" target="_blank">On the Optimization Landscape of Tensor decompositions</a><br>Rong Ge and Tengyu Ma<br>NeurIPS 2017 (<b>oral</b>). Best paper in the NIPS 2016 workshop on nonconvex optimization for ML. Mathematical Programming 2020. <a href="javascript:showb(&#39;tensorlandscape&#39;,&#39;@inproceedings{ge2017optimization,&lt;br&gt;  title={On the optimization landscape of tensor decompositions},&lt;br&gt;  author={Ge, Rong and Ma, Tengyu},&lt;br&gt;  booktitle={Advances in Neural Information Processing Systems},&lt;br&gt;  pages={3653--3663},&lt;br&gt;  year={2017}&lt;br&gt;}&#39;)">bib</a><div id="tensorlandscape_bib"></div></li><br><li><a href="https://arxiv.org/abs/1611.04231" target="_blank">Identity Matters in Deep Learning</a><br>Moritz Hardt and Tengyu Ma<br>ICLR 2017. <a href="javascript:showb(&#39;Identity&#39;,&#39;@article{hardt2016identity,&lt;br&gt;  title={Identity matters in deep learning},&lt;br&gt;  author={Hardt, Moritz and Ma, Tengyu},&lt;br&gt;  journal={International Conference on Learning Representations},&lt;br&gt;  year={2017}&lt;br&gt;}&#39;)">bib</a><div id="Identity_bib"></div></li><br><li><a href="https://arxiv.org/abs/1611.01146" target="_blank">Finding Approximate Local Minima for Nonconvex Optimization in Linear Time</a><br>Naman Agarwal, Zeyuan Allen-Zhu, Brian Bullins, Elad Hazan, and Tengyu Ma<br>STOC 2017. <a href="javascript:showb(&#39;localmin&#39;,&#39;@Article{	  agarwal2017finding,&lt;br&gt;  title		= {Finding approximate local minima for nonconvex&lt;br&gt;		  optimization in linear time},&lt;br&gt;  author	= {Agarwal, Naman and Allen-Zhu, Zeyuan and Bullins, Brian&lt;br&gt;		  and Hazan, Elad and Ma, Tengyu},&lt;br&gt;  journal	= {ACM Symposium on Theory of Computing (STOC)},&lt;br&gt;  year		= {2017}&lt;br&gt;}&lt;br&gt;&#39;)">bib</a><div id="localmin_bib"></div></li><br><li><a href="http://arxiv.org/abs/1605.07272" target="_blank">Matrix Completion has No Spurious Local Minimum</a><br>Rong Ge and Jason D. Lee and Tengyu Ma<br>NeurIPS 2016 (<b>best student paper award</b>). <a href="javascript:showb(&#39;matrixcompletion&#39;,&#39;@inproceedings{ge2016matrix,&lt;br&gt;  title={Matrix completion has no spurious local minimum},&lt;br&gt;  author={Ge, Rong and Lee, Jason D and Ma, Tengyu},&lt;br&gt;  booktitle={Advances in Neural Information Processing Systems},&lt;br&gt;  pages={2973--2981},&lt;br&gt;  year={2016}&lt;br&gt;}&#39;)">bib</a><div id="matrixcompletion_bib"></div></li><br><li><a href="http://arxiv.org/abs/1503.00778" target="_blank">Simple, Efficient, and Neural Algorithms for Sparse Coding</a><br>Sanjeev Arora, Rong Ge, Tengyu Ma, and Ankur Moitra<br>COLT 2015. <a href="javascript:showb(&#39;sparsecoding&#39;,&#39;@article{arora2015simple,&lt;br&gt;  title={Simple, efficient, and neural algorithms for sparse coding},&lt;br&gt;  author={Arora, Sanjeev and Ge, Rong and Ma, Tengyu and Moitra, Ankur},&lt;br&gt;  year={2015},&lt;br&gt;  publisher={Proceedings of Machine Learning Research}&lt;br&gt;}&#39;)">bib</a><div id="sparsecoding_bib"></div></li><br></ul>


<h4>
  <button class="button" onclick="myFunction(&#39;uq&#39;)">
  Uncertainty Quantification
  </button>
</h4>



<ul id="uq" style="display:none;">
<li><a href="https://arxiv.org/abs/2107.05719" target="_blank">Calibrating Predictions to Decisions: A Novel Approach to Multi-Class Calibration</a><br>Shengjia Zhao, Michael P. Kim, Roshni Sahoo, Tengyu Ma, Stefano Ermon<br>NeurIPS 2021. <a href="javascript:showb(&#39;decisioncalibration&#39;,&#39;@article{zhao2021calibrating,&lt;br&gt;  title={Calibrating Predictions to Decisions: A Novel Approach to Multi-Class Calibration},&lt;br&gt;  author={Zhao, Shengjia and Kim, Michael and Sahoo, Roshni and Ma, Tengyu and Ermon, Stefano},&lt;br&gt;  journal={Advances in Neural Information Processing Systems},&lt;br&gt;  volume={34},&lt;br&gt;  year={2021}&lt;br&gt;}&#39;)">bib</a><div id="decisioncalibration_bib"></div></li><br><li><a href="https://arxiv.org/abs/2006.10288" target="_blank">Individual Calibration with Randomized Forecasting</a><br>Shengjia Zhao, Tengyu Ma, and Stefano Ermon<br>ICML 2020. <a href="javascript:showb(&#39;individualc&#39;,&#39;@inproceedings{zhao2020individual,&lt;br&gt;  title={Individual calibration with randomized forecasting},&lt;br&gt;  author={Zhao, Shengjia and Ma, Tengyu and Ermon, Stefano},&lt;br&gt;  booktitle={International Conference on Machine Learning},&lt;br&gt;  pages={11387--11397},&lt;br&gt;  year={2020},&lt;br&gt;  organization={PMLR}&lt;br&gt;}&#39;)">bib</a> <a href="https://github.com/ShengjiaZhao/Individual-Calibration" target="_blank">code</a><div id="individualc_bib"></div></li><br><li><a href="https://arxiv.org/abs/1909.10155" target="_blank">Verified Uncertainty Calibration</a><br>Ananya Kumar, Percy Liang, Tengyu Ma<br>NeurIPS 2019 (<i>spotlight</i>). <a href="javascript:showb(&#39;verified_calibration&#39;,&#39;@inproceedings{{kumar2019calibration, &lt;br&gt; title={Verified Uncertainty Calibration}, &lt;br&gt; author={Kumar, Ananya and Liang, Percy and Ma, Tengyu},&lt;br&gt; booktitle={Advances in Neural Information Processing Systems (NeurIPS)}, &lt;br&gt; year={2019}, pages={3792--3803}, &lt;br&gt; organization={PMLR} &lt;br&gt; }&#39;)">bib</a> <a href="https://github.com/p-lambda/verified_calibration" target="_blank">code</a><div id="verified_calibration_bib"></div></li><br></ul>



<!--

<h4>
  <button class="button" onclick="myFunction('unsup')">
  Unsupervised Learning (Representation Learning and Generative Models)
  </button>
</h4>

<ul id="unsup" style="display:none;">
</ul>
-->



<h4>
  <button class="button" onclick="myFunction(&#39;distml&#39;)">
  Distributed Machine Learning
  </button>
</h4>

<ul id="distml" style="display:none;">
<li><a href="https://arxiv.org/abs/2006.08950" target="_blank">Federated Accelerated Stochastic Gradient Descent</a><br>Honglin Yuan, Tengyu Ma<br>NeurIPS 2020, Best paper in International Workshop on Federated Learning for User Privacy and Data Confidentiality in Conjunction with ICML 2020 (FL-ICML'20). <a href="javascript:showb(&#39;fedac&#39;,&#39;@article{yuan2020federated, &lt;br&gt; title={Federated Accelerated Stochastic Gradient Descent}, &lt;br&gt; author={Yuan, Honglin and Ma, Tengyu}, &lt;br&gt; journal={arXiv preprint arXiv:2006.08950}, &lt;br&gt; year={2020} &lt;br&gt; }&#39;)">bib</a> <a href="https://github.com/hongliny/FedAc-NeurIPS20" target="_blank">code</a><div id="fedac_bib"></div></li><br><li><a href="http://arxiv.org/abs/1507.07595" target="_blank">Distributed Stochastic Variance Reduced Gradient Methods by Sampling Extra Data with Replacement</a><br>Jason Lee, Qihang Lin, Tengyu Ma, Tianbao Yang<br>JMLR, 18(122):1−43, 2017. <a href="javascript:showb(&#39;dsvrg&#39;,&#39;@article{lee2017distributed,&lt;br&gt;  title={Distributed stochastic variance reduced gradient methods by sampling extra data with replacement},&lt;br&gt;  author={Lee, Jason D and Lin, Qihang and Ma, Tengyu and Yang, Tianbao},&lt;br&gt;  journal={The Journal of Machine Learning Research},&lt;br&gt;  volume={18},&lt;br&gt;  number={1},&lt;br&gt;  pages={4404--4446},&lt;br&gt;  year={2017},&lt;br&gt;  publisher={JMLR. org}&lt;br&gt;}&#39;)">bib</a><div id="dsvrg_bib"></div></li><br><li><a href="http://arxiv.org/abs/1506.07216" target="_blank">Communication Lower Bounds for Statistical Estimation Problems via a Distributed Data Processing Inequality</a><br>Mark Braverman, Ankit Garg, Huy L. Nguyen, Tengyu Ma, and David P. Woodruff<br>STOC 2016. <a href="javascript:showb(&#39;sdpi&#39;,&#39;@inproceedings{braverman2016communication,&lt;br&gt;  title={Communication lower bounds for statistical estimation problems via a distributed data processing inequality},&lt;br&gt;  author={Braverman, Mark and Garg, Ankit and Ma, Tengyu and Nguyen, Huy L and Woodruff, David P},&lt;br&gt;  booktitle={Proceedings of the forty-eighth annual ACM symposium on Theory of Computing},&lt;br&gt;  pages={1011--1020},&lt;br&gt;  year={2016}&lt;br&gt;}&#39;)">bib</a><div id="sdpi_bib"></div></li><br><li><a href="http://arxiv.org/abs/1405.1665" target="_blank">On the Communication Cost of Distributed Statistical Estimation and Dimensionality</a><br>Ankit Garg and Huy Nguyễn and Tengyu Ma<br>NeurIPS 2014 (<b>oral</b>). <a href="javascript:showb(&#39;distlower&#39;,&#39;@inproceedings{garg2014communication,&lt;br&gt;  title={On communication cost of distributed statistical estimation and dimensionality},&lt;br&gt;  author={Garg, Ankit and Ma, Tengyu and Nguyen, Huy},&lt;br&gt;  booktitle={Advances in Neural Information Processing Systems},&lt;br&gt;  pages={2726--2734},&lt;br&gt;  year={2014}&lt;br&gt;}&#39;)">bib</a><div id="distlower_bib"></div></li><br></ul>


<h4>
  <button class="button" onclick="myFunction(&#39;otherml&#39;)">
  Provable Machine Learning Algorithms
  </button>
</h4>

<ul id="otherml" style="display:none;">
<li><a href="https://arxiv.org/abs/1806.10586" target="_blank">Approximability of Discriminators Implies Diversity in GANs</a><br>Yu Bai, Tengyu Ma, Andrej Risteski<br>ICLR 2019. <a href="javascript:showb(&#39;approxgans&#39;,&#39;@inproceedings{bai2018approximability,&lt;br&gt;  title={Approximability of Discriminators Implies Diversity in GANs},&lt;br&gt;  author={Bai, Yu and Ma, Tengyu and Risteski, Andrej},&lt;br&gt;  booktitle={International Conference on Learning Representations},&lt;br&gt;  year={2018}&lt;br&gt;}&#39;)">bib</a><div id="approxgans_bib"></div></li><br><li><a href="https://arxiv.org/abs/1703.00573" target="_blank">Generalization and Equilibrium in Generative Adversarial Nets (GANs)</a><br>Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi Zhang<br>ICML 2017. <a href="javascript:showb(&#39;gansgen&#39;,&#39;@inproceedings{arora2017generalization,&lt;br&gt;  title={Generalization and equilibrium in generative adversarial nets (GANs)},&lt;br&gt;  author={Arora, Sanjeev and Ge, Rong and Liang, Yingyu and Ma, Tengyu and Zhang, Yi},&lt;br&gt;  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},&lt;br&gt;  pages={224--232},&lt;br&gt;  year={2017}&lt;br&gt;}&#39;)">bib</a><div id="gansgen_bib"></div></li><br><li><a href="https://arxiv.org/abs/1612.08795" target="_blank">Provable learning of Noisy-or Networks</a><br>Sanjeev Arora, Rong Ge, Tengyu Ma, and Andrej Risteski<br>STOC 2017. <a href="javascript:showb(&#39;noisyor&#39;,&#39;@inproceedings{arora2017provable,&lt;br&gt;  title={Provable learning of noisy-or networks},&lt;br&gt;  author={Arora, Sanjeev and Ge, Rong and Ma, Tengyu and Risteski, Andrej},&lt;br&gt;  booktitle={Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing},&lt;br&gt;  pages={1057--1066},&lt;br&gt;  year={2017}&lt;br&gt;}&#39;)">bib</a><div id="noisyor_bib"></div></li><br><li><a href="https://arxiv.org/abs/1610.01132" target="_blank">A Non-generative Framework and Convex Relaxations for Unsupervised Learning</a><br>Elad Hazan and Tengyu Ma<br>NeurIPS 2016. <a href="javascript:showb(&#39;Non-generative&#39;,&#39;@inproceedings{hazan2016non,&lt;br&gt;  title={A non-generative framework and convex relaxations for unsupervised learning},&lt;br&gt;  author={Hazan, Elad and Ma, Tengyu},&lt;br&gt;  booktitle={Advances in Neural Information Processing Systems},&lt;br&gt;  pages={3306--3314},&lt;br&gt;  year={2016}&lt;br&gt;}&#39;)">bib</a><div id="Non-generative_bib"></div></li><br><li><a href="https://arxiv.org/abs/1610.01980" target="_blank">Polynomial-time Tensor Decompositions with Sum-of-squares</a><br>Tengyu Ma, Jonathan Shi, and David Steurer<br>STOC 2017. <a href="javascript:showb(&#39;sos&#39;,&#39;@inproceedings{ma2016polynomial,&lt;br&gt;  title={Polynomial-time tensor decompositions with sum-of-squares},&lt;br&gt;  author={Ma, Tengyu and Shi, Jonathan and Steurer, David},&lt;br&gt;  booktitle={2016 IEEE 57th Annual Symposium on Foundations of Computer Science (FOCS)},&lt;br&gt;  pages={438--446},&lt;br&gt;  year={2016},&lt;br&gt;  organization={IEEE}&lt;br&gt;}&#39;)">bib</a><div id="sos_bib"></div></li><br><li><a href="https://arxiv.org/abs/1605.08491" target="_blank">Provable Algorithms for Inference in Topic Models</a><br>Sanjeev Arora, Rong Ge, Frederic Koehler, Tengyu Ma, and Ankur Moitra<br>ICML 2016. <a href="javascript:showb(&#39;topic&#39;,&#39;@inproceedings{arora2016provable,&lt;br&gt;  title={Provable algorithms for inference in topic models},&lt;br&gt;  author={Arora, Sanjeev and Ge, Rong and Koehler, Frederic and Ma, Tengyu and Moitra, Ankur},&lt;br&gt;  booktitle={International Conference on Machine Learning},&lt;br&gt;  pages={2859--2867},&lt;br&gt;  year={2016}&lt;br&gt;}&#39;)">bib</a><div id="topic_bib"></div></li><br><li><a href="http://arxiv.org/abs/1511.05653" target="_blank">Why are deep nets reversible: A simple theory, with implications for training</a><br>Sanjeev Arora, Yingyu Liang, and Tengyu Ma<br>ICLR workshop 2016. <a href="javascript:showb(&#39;reversible&#39;,&#39;@article{arora2015deep,&lt;br&gt;  title={Why are deep nets reversible: A simple theory, with implications for training},&lt;br&gt;  author={Arora, Sanjeev and Liang, Yingyu and Ma, Tengyu},&lt;br&gt;  journal={arXiv preprint arXiv:1511.05653},&lt;br&gt;  year={2015}&lt;br&gt;}&#39;)">bib</a><div id="reversible_bib"></div></li><br><li><a href="http://arxiv.org/abs/1504.05287" target="_blank">Decomposing Overcomplete 3rd Order Tensors using Sum-of-Squares Algorithms</a><br>Rong Ge and Tengyu Ma<br>RANDOM/APPROX 2015. <a href="javascript:showb(&#39;sostensor&#39;,&#39;@inproceedings{ge2015decomposing,&lt;br&gt;  title={Decomposing Overcomplete 3rd Order Tensors using Sum-of-Squares Algorithms},&lt;br&gt;  author={Ge, Rong and Ma, Tengyu},&lt;br&gt;  booktitle={Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques (APPROX/RANDOM 2015)},&lt;br&gt;  year={2015},&lt;br&gt;  organization={Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik}&lt;br&gt;}&#39;)">bib</a><div id="sostensor_bib"></div></li><br><li><a href="http://arxiv.org/abs/1310.6343" target="_blank">Provable Bounds for Learning Some Deep Representations</a><br>Sanjeev Arora, Aditya Bhaskara, Rong Ge, and Tengyuu Ma<br>ICML 2014. <a href="javascript:showb(&#39;provabledeep&#39;,&#39;@inproceedings{arora2014provable,&lt;br&gt;  title={Provable bounds for learning some deep representations},&lt;br&gt;  author={Arora, Sanjeev and Bhaskara, Aditya and Ge, Rong and Ma, Tengyu},&lt;br&gt;  booktitle={International Conference on Machine Learning},&lt;br&gt;  pages={584--592},&lt;br&gt;  year={2014}&lt;br&gt;}&#39;)">bib</a><div id="provabledeep_bib"></div></li><br></ul>




<h4>
  <button class="button" onclick="myFunction(&#39;others&#39;)">
  Other Papers 
  </button>
</h4>

<ul id="others" style="display:none;">
<li><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2857656" target="_blank">Optimal Design of Process Flexility for General Production Systems</a><br>Xi Chen, Tengyu Ma, Jiawei Zhang, Yuan Zhou<br>Operations research 2018. <a href="javascript:showb(&#39;prodctioin-system&#39;,&#39;&lt;br&gt;@article{chen2019optimal,&lt;br&gt;  title={Optimal design of process flexibility for general production systems},&lt;br&gt;  author={Chen, Xi and Ma, Tengyu and Zhang, Jiawei and Zhou, Yuan},&lt;br&gt;  journal={Operations Research},&lt;br&gt;  volume={67},&lt;br&gt;  number={2},&lt;br&gt;  pages={516--531},&lt;br&gt;  year={2019},&lt;br&gt;  publisher={INFORMS}&lt;br&gt;}&#39;)">bib</a><div id="prodctioin-system_bib"></div></li><br><li><a href="http://arxiv.org/abs/1507.06370" target="_blank">Sum-of-Squares Lower Bounds for Sparse PCA</a><br>Tengyu Ma and Avi Wigderson<br>NeurIPS 2015. <a href="javascript:showb(&#39;sparsepca&#39;,&#39;@inproceedings{ma2015sum,&lt;br&gt;  title={Sum-of-squares lower bounds for sparse PCA},&lt;br&gt;  author={Ma, Tengyu and Wigderson, Avi},&lt;br&gt;  booktitle={Advances in Neural Information Processing Systems},&lt;br&gt;  pages={1612--1620},&lt;br&gt;  year={2015}&lt;br&gt;}&#39;)">bib</a><div id="sparsepca_bib"></div></li><br><li><a href="http://arxiv.org/abs/1107.2188" target="_blank">Simulated Greedy Algorithms for Several Submodular Matroid Secretary Problems</a><br>Tengyu Ma, Bo Tang, and Yajun Wang<br>Theory of Computing Systems 2016. <a href="javascript:showb(&#39;matrioid&#39;,&#39;@article{ma2016simulated,&lt;br&gt;  title={The simulated greedy algorithm for several submodular matroid secretary problems},&lt;br&gt;  author={Ma, Tengyu and Tang, Bo and Wang, Yajun},&lt;br&gt;  journal={Theory of Computing Systems},&lt;br&gt;  volume={58},&lt;br&gt;  number={4},&lt;br&gt;  pages={681--706},&lt;br&gt;  year={2016},&lt;br&gt;  publisher={Springer}&lt;br&gt;}&#39;)">bib</a><div id="matrioid_bib"></div></li><br></ul>

<h3 id="teaching">Teaching</h3>

<ul>
  <li><a href="http://web.stanford.edu/class/stats214/" target="_blank">Statistical/Machine Learning Theory</a> (CS229T/STATS231, CS229M/STATS214), Autumn 2018, Winter 2021</li>
  <li><a href="http://cs229.stanford.edu/" target="_blank">Machine Learning</a> (CS229/STATS229), Spring 2019-2020, Autumn 2020</li>
  <li><a href="http://web.stanford.edu/class/stats205/" target="_blank">Introduction to Nonparametric Statistics</a> (STATS205), Autumn 2019, Spring 2021</li>
</ul>

<h3 id="service">Service</h3>

<ul>
  <li>Area Chair or PC committee: AAAI 2019-2020, ICLR 2019-2021, NeurIPS 2019-2021, ALT 2017-2018, ITCS 2018, STOC 2020, COLT 2020-2021</li>
</ul>


<h3 id="awards">Awards</h3>

<ul>
  <li>Sloan Research Fellowships 2021</li>
  <li>ACM Doctoral Dissertation Award Honorable Mention 2018</li>
  <li>COLT Best Paper Award 2018</li>
  <li>NIPS Best Student Paper Award 2016</li>
  <li>Princeton Honorific Fellowship</li>
  <li>8th Place in William Lowell Putnam Mathematical Competition 2010</li>
<li>Silver Medal in International Mathematical Olympiad (IMO) 2007
</li></ul>


<script>



function myFunction(name){
  var x = document.getElementById(name)
  if (x.style.display === "none"){
    x.style.display = null
  } else {
    x.style.display = "none"
  }
}

function showb(name, bibtex){
  if (!document.getElementById(name+"_bib").innerHTML.includes('pre')) {
    document.getElementById(name+"_bib").innerHTML += '<pre style="font-size: 10px">' + bibtex + '</pre>'
  } else {
    document.getElementById(name+"_bib").innerHTML = ''
  }

}

function addpaper(link, title, author, conference, year, bibtex, name, blockname, codelink, slides, slidespdf) {

  re = "<li><a href=" + link + " target=\"_blank\""+ ">" +title + "</a><br>" + author + "<br>" + conference + ' ' + year + ". "  
  re += '<a href="javascript:showb(\''+ name + '\'' + ',\'' + bibtex + '\')">bib<\/a>'
  if (codelink != null){
    re += ' <a href=\"' + codelink + '\"' + ' target=\"_blank\"' + '>code<\/a>'
  }
  if (slides != null){
    re += ' <a href=\"slides\/' + slides + '.pptx\"' + ' target=\"_blank\"' + '>slides(pptx)<\/a>' + ' '
    re += '<a href=\"slides\/' + slides + '.pdf\"' + ' target=\"_blank\"' + '>slides(pdf)<\/a>' 
  }
  re += '<div id="' + name + '_bib"></div>'
  re += '<\/li>'
  re += '<br>'  
  document.getElementById(blockname).innerHTML += re 

}

var icml = 'ICML'
var iclr = 'ICLR'
var colt = 'COLT'
var tacl = 'TACL'
var acl = 'ACL'
var stoc = 'STOC'
var jmlr = 'JMLR'
var neurips = 'NeurIPS'
var aistats = 'AISTATS'
var manu = 'Manuscript'


bibtexstring = `@article{haochen2022beyond,
  title={Beyond Separability: Analyzing the Linear Transferability of Contrastive Representations to Related Subpopulations},
  author={HaoChen, Jeff Z and Wei, Colin and Kumar, Ananya and Ma, Tengyu},
  journal={arXiv preprint arXiv:2204.02683},
  year={2022}
}
`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2204.02683",
         "Beyond Separability: Analyzing the Linear Transferability of Contrastive Representations to Related Subpopulations",
         "Jeff Z. HaoChen, Colin Wei, Ananya Kumar, Tengyu Ma", 
         manu, 
         "2022", 
         bibtexstring,
         "uda-contrastive-theory", 
         'manuscript',
         null,
         null);

bibtexstring = `@article{shen2022connect,
  title={Connect, Not Collapse: Explaining Contrastive Learning for Unsupervised Domain Adaptation},
  author={Shen, Kendrick and Jones, Robbie and Kumar, Ananya and Xie, Sang Michael and HaoChen, Jeff Z and Ma, Tengyu and Liang, Percy},
  journal={arXiv preprint arXiv:2204.00570},
  year={2022}
}
`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2204.00570",
         "Connect, Not Collapse: Explaining Contrastive Learning for Unsupervised Domain Adaptation",
         "Kendrick Shen, Robbie Jones, Ananya Kumar, Sang Michael Xie, Jeff Z. HaoChen, Tengyu Ma, Percy Liang", 
         manu, 
         "2022", 
         bibtexstring,
         "uda-contrastive", 
         'manuscript',
         null,
         null);


bibtexstring = `@misc{xie2021explanation,
      title={An Explanation of In-context Learning as Implicit Bayesian Inference}, 
      author={Sang Michael Xie and Aditi Raghunathan and Percy Liang and Tengyu Ma},
      year={2021},
      eprint={2111.02080},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2111.02080",
         "An Explanation of In-context Learning as Implicit Bayesian Inference",
         "Sang Michael Xie, Aditi Raghunathan, Percy Liang, Tengyu Ma", 
         iclr, 
         "2022", 
         bibtexstring,
         "in-context-bayesian", 
         'manuscript',
         null,
         null);





bibtexstring = `@misc{liu2021selfsupervised,
      title={Self-supervised Learning is More Robust to Dataset Imbalance}, 
      author={Hong Liu and Jeff Z. HaoChen and Adrien Gaidon and Tengyu Ma},
      year={2021},
      eprint={2110.05025},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2110.05025",
         "Self-supervised Learning is More Robust to Dataset Imbalance",
         "Hong Liu, Jeff Z. HaoChen, Adrien Gaidon, Tengyu Ma", 
         iclr, 
         "2022, <i>spotlight</i>", 
         bibtexstring,
         "ssl-robustness", 
         'manuscript',
         'https://github.com/Liuhong99/Imbalanced-SSL',
         null);


bibtexstring = `@article{kumar2022fine,
  title={Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution},
  author={Kumar, Ananya and Raghunathan, Aditi and Jones, Robbie and Ma, Tengyu and Liang, Percy},
  journal={arXiv preprint arXiv:2202.10054},
  year={2022}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2202.10054",
         "Fine-Tuning Distorts Pretrained Features and Underperforms Out-of-Distribution",
         "Ananya Kumar, Aditi Raghunathan, Robbie Matthew Jones, Tengyu Ma, Percy Liang", 
         iclr, 
         "2022, <b>oral</b>", 
         bibtexstring,
         "lpfp", 
         'manuscript',
         null,
         null);



bibtexstring = `@misc{glasgow2021sharp,
      title={Sharp Bounds for Federated Averaging (Local SGD) and Continuous Perspective}, 
      author={Margalit Glasgow and Honglin Yuan and Tengyu Ma},
      year={2021},
      eprint={2111.03741},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2111.03741",
         "Sharp Bounds for Federated Averaging (Local SGD) and Continuous Perspective",
         "Margalit Glasgow, Honglin Yuan, Tengyu Ma", 
         aistats, 
         "2022", 
         bibtexstring,
         "fedavg-sharp", 
         'manuscript',
         null,
         null);


bibtexstring = `@article{wang2020beyond,
  title={Beyond lazy training for over-parameterized tensor decomposition},
  author={Wang, Xiang and Wu, Chenwei and Lee, Jason D and Ma, Tengyu and Ge, Rong},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={21934--21944},
  year={2020}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2010.11356",
         "Beyond Lazy Training for Over-parameterized Tensor Decomposition",
         "Xiang Wang, Chenwei Wu, Jason D. Lee, Tengyu Ma, Rong Ge", 
         neurips, 
         "2020", 
         bibtexstring,
         "beyondlazytensor", 
         'opt',
         null,
         null);



bibtexstring = `@article{wei2021pretrained,
  title={Why do pretrained language models help in downstream tasks? an analysis of head and prompt tuning},
  author={Wei, Colin and Xie, Sang Michael and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}`.replace(/\n/g, '<br>')

addpaper("http://arxiv.org/abs/2106.09226",
         "Why Do Pretrained Language Models Help in Downstream Tasks? An Analysis of Head and Prompt Tuning",
         "Colin Wei, Sang Michael Xie, Tengyu Ma", 
         neurips, 
         "2021, <i>spotlight</i>", 
         bibtexstring,
         "lm", 
         'representation',
         'https://github.com/sangmichaelxie/pretraining_analysis',
         null);

bibtexstring = `@article{haochen2021provable,
  title={Provable guarantees for self-supervised deep learning with spectral contrastive loss},
  author={HaoChen, Jeff Z and Wei, Colin and Gaidon, Adrien and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2106.04156",
         "Provable Guarantees for Self-Supervised Deep Learning with Spectral Contrastive Loss",
         "Jeff Z. HaoChen, Colin Wei, Adrien Gaidon, Tengyu Ma", 
         neurips, 
         "2021, <b>oral</b>", 
         bibtexstring,
         "selfsup", 
         'representation',
         'https://github.com/jhaochenz/spectral_contrastive_learning',
         'selfsup');


bibtexstring = `@misc{pan2021plan,
      title={Plan Better Amid Conservatism: Offline Multi-Agent Reinforcement Learning with Actor Rectification}, 
      author={Ling Pan and Longbo Huang and Tengyu Ma and Huazhe Xu},
      year={2021},
      eprint={2111.11188},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}`.replace(/\n/g, '<br>')

addpaper("arxiv.org/abs/2111.11188",
         "Plan Better Amid Conservatism: Offline Multi-Agent Reinforcement Learning with Actor Rectification",
         "Ling Pan, Longbo Huang, Tengyu Ma, Huazhe Xu", 
         manu, 
         "2021", 
         bibtexstring,
         "omar", 
         'manuscript',
         null,
         null);


bibtexstring = `@article{kumar2021dr3,
  title={DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization},
  author={Kumar, Aviral and Agarwal, Rishabh and Ma, Tengyu and Courville, Aaron and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2112.04716},
  year={2021}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2112.04716",
         "DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization",
         "Aviral Kumar, Rishabh Agarwal, Tengyu Ma, Aaron Courville, George Tucker, Sergey Levine", 
         iclr, 
         "2022, <i>spotlight</i>", 
         bibtexstring,
         "dr3", 
         'RL',
         null,
         null);



bibtexstring = `@article{luo2021learning,
  title={Learning Barrier Certificates: Towards Safe Reinforcement Learning with Zero Training-time Violations},
  author={Luo, Yuping and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2108.01846",
         "Learning Barrier Certificates: Towards Safe Reinforcement Learning with Zero Training-time Violations",
         "Yuping Luo, Tengyu Ma", 
         neurips, 
         "2021", 
         bibtexstring,
         "barrercertificate", 
         'RL',
         'https://github.com/roosephu/crabs',
         null);





bibtexstring = `@misc{wei2021statistically,
      title={Statistically Meaningful Approximation: a Case Study on Approximating Turing Machines with Transformers}, 
      author={Colin Wei and Yining Chen and Tengyu Ma},
      year={2021},
      eprint={2107.13163},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2107.13163",
         "Statistically Meaningful Approximation: a Case Study on Approximating Turing Machines with Transformers",
         "Colin Wei, Yining Chen, Tengyu Ma", 
         manu, 
         "2021", 
         bibtexstring,
         "statistcalapprox", 
         'manuscript',
         null,
         null);

bibtexstring = `@article{zhao2021calibrating,
  title={Calibrating Predictions to Decisions: A Novel Approach to Multi-Class Calibration},
  author={Zhao, Shengjia and Kim, Michael and Sahoo, Roshni and Ma, Tengyu and Ermon, Stefano},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2107.05719",
         "Calibrating Predictions to Decisions: A Novel Approach to Multi-Class Calibration",
         "Shengjia Zhao, Michael P. Kim, Roshni Sahoo, Tengyu Ma, Stefano Ermon", 
         neurips, 
         "2021", 
         bibtexstring,
         "decisioncalibration", 
         'uq',
         null,
         null);



bibtexstring = `@article{damian2021label,
  title={Label noise sgd provably prefers flat global minimizers},
  author={Damian, Alex and Ma, Tengyu and Lee, Jason D},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2106.06530",
         "Label Noise SGD Provably Prefers Flat Global Minimizers",
         "Alex Damian, Tengyu Ma, Jason Lee", 
         neurips, 
         "2021", 
         bibtexstring,
         "labelnoise-global", 
         'generalization',
         null,
         null);


bibtexstring = `@article{thomas2021safe,
  title={Safe Reinforcement Learning by Imagining the Near Future},
  author={Thomas, Garrett and Luo, Yuping and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}`.replace(/\n/g, '<br>')



addpaper("https://arxiv.org/abs/2202.07789",
         "Safe Reinforcement Learning by Imagining the Near Future",
         "Garrett Thomas, Yuping Luo, Tengyu Ma", 
         neurips, 
         "2021", 
         bibtexstring,
         "smbpo", 
         'RL',
         'https://github.com/gwthomas/Safe-MBPO',
         null);

bibtexstring = `@misc{ma2021local,
      title={Why Do Local Methods Solve Nonconvex Problems?}, 
      author={Tengyu Ma},
      year={2021},
      eprint={2103.13462},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}`.replace(/\n/g, '<br>')

addpaper("http://arxiv.org/abs/2103.13462",
         "Why Do Local Methods Solve Nonconvex Problems?",
         "Tengyu Ma", 
         "", 
         "Chapter 21 of <a href='https://www.cambridge.org/core/books/beyond-the-worstcase-analysis-of-algorithms/8A8128BBF7FC2857471E9CA52E69AC21' target='_blank'>Beyond the Worst-Case Analysis of Algorithms</a>", 
         bibtexstring,
         "nonconvexsurvey", 
         'opt');


bibtexstring = `@inproceedings{xu2021fine,
  title={Fine-grained gap-dependent bounds for tabular mdps via adaptive multi-step bootstrap},
  author={Xu, Haike and Ma, Tengyu and Du, Simon},
  booktitle={Conference on Learning Theory},
  pages={4438--4472},
  year={2021},
  organization={PMLR}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2102.04692",
         "Fine-Grained Gap-Dependent Bounds for Tabular MDPs via Adaptive Multi-Step Bootstrap",
         "Haike Xu, Tengyu Ma, Simon S. Du", 
         colt, 
         "2021", 
         bibtexstring,
         "gap", 
         "RL", 
         null, 
         null);



bibtexstring = `@article{dong2021provable,
  title={Provable model-based nonlinear bandit and reinforcement learning: Shelve optimism, embrace virtual curvature},
  author={Dong, Kefan and Yang, Jiaqi and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2102.04168",
         "Provable Model-based Nonlinear Bandit and Reinforcement Learning: Shelve Optimism, Embrace Virtual Curvature",
         "Kefan Dong, Jiaqi Yang, Tengyu Ma", 
         neurips, 
         "2021", 
         bibtexstring,
         "viol", 
         'RL',
         null,
         'viol');

bibtexstring = `@inproceedings{wei2020theoretical,
  title={Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data},
  author={Wei, Colin and Shen, Kendrick and Chen, Yining and Ma, Tengyu},
  booktitle={International Conference on Learning Representations},
  year={2020}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2010.03622",
         "Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data",
         "Colin Wei, Kendrick Shen, Yining Chen, Tengyu Ma", 
         iclr, 
         "2021, <b>oral</b>", 
         bibtexstring,
         "Self-training-expansion", 
         'representation', 
         null, 
         "self_training");

bibtexstring = `@inproceedings{haochen2021shape,
  title={Shape matters: Understanding the implicit bias of the noise covariance},
  author={HaoChen, Jeff Z and Wei, Colin and Lee, Jason and Ma, Tengyu},
  booktitle={Conference on Learning Theory},
  pages={2315--2357},
  year={2021},
  organization={PMLR}
}`.replace(/\n/g, '<br>')


addpaper("https://arxiv.org/abs/2006.08680",
         "Shape Matters: Understanding the Implicit Bias of the Noise Covariance",
         "Jeff Z. HaoChen, Colin Wei, Jason D. Lee, Tengyu Ma", 
         colt, 
         "2021", 
         bibtexstring,
         "shape", 
         'generalization',
         'https://github.com/jhaochenz/noise-implicit-bias', 
         'shape_matters');


bibtexstring = `@misc{liu2020metalearning,
      title={Meta-learning Transferable Representations with a Single Target Domain}, 
      author={Hong Liu and Jeff Z. HaoChen and Colin Wei and Tengyu Ma},
      year={2020},
      eprint={2011.01418},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2011.01418",
         "Meta-learning Transferable Representations with a Single Target Domain",
         "Hong Liu, Jeff Z. HaoChen, Colin Wei, Tengyu Ma", 
         manu, 
         "2020", 
         bibtexstring,
         "merlin", 
         'representation');

/*
bibtexstring = `@misc{chen2021iterative,
      title={Iterative Feature Matching: Toward Provable Domain Generalization with Logarithmic Environments}, 
      author={Yining Chen and Elan Rosenfeld and Mark Sellke and Tengyu Ma and Andrej Risteski},
      year={2021},
      eprint={2106.09913},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2106.09913",
         "Iterative Feature Matching: Toward Provable Domain Generalization with Logarithmic Environments",
         "Yining Chen, Elan Rosenfeld, Mark Sellke, Tengyu Ma, Andrej Risteski", 
         manu, 
         "2021", 
         bibtexstring,
         "DG", 
         'manuscript',
         null,
         null);
*/
bibtexstring=`@inproceedings{xie2020n,
  title={In-N-Out: Pre-Training and Self-Training using Auxiliary Information for Out-of-Distribution Robustness},
  author={Xie, Sang Michael and Kumar, Ananya and Jones, Robbie and Khani, Fereshte and Ma, Tengyu and Liang, Percy},
  booktitle={International Conference on Learning Representations},
  year={2020}
}`.replace(/\n/g, '<br>')


addpaper("https://arxiv.org/abs/2012.04550",
         "In-N-Out: Pre-Training and Self-Training using Auxiliary Information for Out-of-Distribution Robustness",
         "Sang Michael Xie&#42, Ananya Kumar&#42, Robbie Jones&#42, Fereshte Khani, Tengyu Ma, Percy Liang", 
         iclr, 
         "2021", 
         bibtexstring,
         "in-and-out", 
         'representation', 
         'https://worksheets.codalab.org/worksheets/0x2613c72d4f3f4fbb94e0a32c17ce5fb0');


bibtexstring=`@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James Y and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={14129--14142},
  year={2020}
}`.replace(/\n/g, '<br>')


addpaper("https://arxiv.org/abs/2005.13239",
         "MOPO: Model-based Offline Policy Optimization",
         "Tianhe Yu&#42, Garrett Thomas&#42, Lantao Yu, Stefano Ermon, James Zou, Sergey Levine, Chelsea Finn&#42, Tengyu Ma&#42", 
         neurips, 
         "2020", 
         bibtexstring,
         "mopo", 
         'RL',
         'https://github.com/tianheyu927/mopo');

bibtexstring=`@article{lin2020model,
  title={Model-based adversarial meta-reinforcement learning},
  author={Lin, Zichuan and Thomas, Garrett and Yang, Guangwen and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={10161--10173},
  year={2020}
}`.replace(/\n/g, '<br>')


addpaper("https://arxiv.org/abs/2006.08875",
         "Model-based Adversarial Meta-Reinforcement Learning",
         "Zichuan Lin, Garrett Thomas, Guangwen Yang, Tengyu Ma", 
         neurips, 
         "2020", 
         bibtexstring,
         "admrl", 
         'RL', 
         'https://github.com/LinZichuan/AdMRL');

bibtexstring = `@inproceedings{xie2021composed,
  title={Composed Fine-Tuning: Freezing Pre-Trained Denoising Autoencoders for Improved Generalization},
  author={Xie, Sang Michael and Ma, Tengyu and Liang, Percy},
  booktitle={International Conference on Machine Learning},
  pages={11424--11435},
  year={2021},
  organization={PMLR}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2006.16205",
         "Composed Fine-Tuning: Freezing Pre-Trained Denoising Autoencoders for Improved Generalization",
         "Sang Michael Xie, Tengyu Ma, Percy Liang", 
         icml, 
         "2021", 
         bibtexstring,
         "unlabeledoutput", 
         'representation',
         'https://github.com/p-lambda/composed_finetuning');


bibtexstring = `@inproceedings{cao2020heteroskedastic,
  title={Heteroskedastic and Imbalanced Deep Learning with Adaptive Regularization},
  author={Cao, Kaidi and Chen, Yining and Lu, Junwei and Arechiga, Nikos and Gaidon, Adrien and Ma, Tengyu},
  booktitle={International Conference on Learning Representations},
  year={2020}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2006.15766",
         "Heteroskedastic and Imbalanced Deep Learning with Adaptive Regularization",
         "Kaidi Cao, Yining Chen, Junwei Lu, Nikos Arechiga, Adrien Gaidon, Tengyu Ma", 
         iclr, 
         "2021", 
         bibtexstring,
         "Heteroskedastic", 
         'representation',
         'https://github.com/kaidic/HAR');

addpaper("https://arxiv.org/abs/2006.14481",
         "Active Online Learning with Hidden Shifting Domains",
         "Yining Chen, Haipeng Luo, Tengyu Ma, Chicheng Zhang", 
         aistats, 
         "2020", 
         '@article{chen2020active, <br> title={Active Online Domain Adaptation}, <br> author={Chen, Yining and Luo, Haipeng and Ma, Tengyu and Zhang, Chicheng},<br> journal={arXiv preprint arXiv:2006.14481}, <br> year={2020} <br>}',
         "qufur", 
         'RL',
         'https://github.com/cynnjjs/online_active_AISTATS');

addpaper("https://arxiv.org/abs/2006.10032",
         "Self-training Avoids Using Spurious Features Under Domain Shift",
         "Yining Chen&#42, Colin Wei&#42, Ananya Kumar, Tengyu Ma", 
         neurips, 
         "2020", 
         '@article{chen2020self, <br> title={Self-training Avoids Using Spurious Features Under Domain Shift}, <br> author={Chen, Yining and Wei, Colin and Kumar, Ananya and Ma, Tengyu}, <br> journal={arXiv preprint arXiv:2006.10032}, <br> year={2020} <br> }',
         "Self-Training", 
         'representation',
         'https://github.com/cynnjjs/spurious_feature_NeuRIPS');



addpaper("https://arxiv.org/abs/2006.08950",
         "Federated Accelerated Stochastic Gradient Descent",
         "Honglin Yuan, Tengyu Ma", 
         neurips, 
         "2020, Best paper in International Workshop on Federated Learning for User Privacy and Data Confidentiality in Conjunction with ICML 2020 (FL-ICML'20)",
         '@article{yuan2020federated, <br> title={Federated Accelerated Stochastic Gradient Descent}, <br> author={Yuan, Honglin and Ma, Tengyu}, <br> journal={arXiv preprint arXiv:2006.08950}, <br> year={2020} <br> }',
         "fedac", 
         'distml',
         'https://github.com/hongliny/FedAc-NeurIPS20');


bibtexstring = `@inproceedings{nakkiran2020optimal,
  title={Optimal Regularization can Mitigate Double Descent},
  author={Nakkiran, Preetum and Venkat, Prayaag and Kakade, Sham M and Ma, Tengyu},
  booktitle={International Conference on Learning Representations},
  year={2020}
}`.replace(/\n/g, '<br>')


addpaper("https://arxiv.org/abs/2003.01897",
         "Optimal Regularization Can Mitigate Double Descent",
         "Preetum Nakkiran, Prayaag Venkat, Sham Kakade, Tengyu Ma", 
         iclr, 
         "2021", 
         bibtexstring,
         "dd", 
         'generalization');


addpaper("https://arxiv.org/abs/1910.05927",
         "On the Expressivity of Neural Networks for Deep Reinforcement Learning",
         "Kefan Dong&#42, Yuping Luo&#42, Tengyu Ma", 
         "ICML", 
         "2020", 
         '@inproceedings{dong2020expressivity, <br> title={On the Expressivity of Neural Networks for Deep Reinforcement Learning}, <br> author={Dong, Kefan and Luo, Yuping and Yu, Tianhe and Finn, Chelsea and Ma, Tengyu}, <br> booktitle={International Conference on Machine Learning}, <br> year={2020}<br>}',
         "ExpressivityRL", 
         'RL',
         'https://github.com/roosephu/boots');


addpaper("https://arxiv.org/abs/2002.12915",
         "The Implicit and Explicit Regularization Effects of Dropout",
         "Colin Wei, Sham Kakade, Tengyu Ma", 
         icml, 
         "2020", 
         '@inproceedings{wei2020implicit, <br> title={The Implicit and Explicit Regularization Effects of Dropout}, <br> author={Wei, Colin and Kakade, Sham and Ma, Tengyu}, <br> booktitle={International Conference on Machine Learning}, <br> year={2020} <br>}',
         "dropout", 
         'generalization',
         'https://github.com/cwein3/dropout-analytical');



bibtexstring = `@inproceedings{zhao2020individual,
  title={Individual calibration with randomized forecasting},
  author={Zhao, Shengjia and Ma, Tengyu and Ermon, Stefano},
  booktitle={International Conference on Machine Learning},
  pages={11387--11397},
  year={2020},
  organization={PMLR}
}`.replace(/\n/g, '<br>')





addpaper("https://arxiv.org/abs/2006.10288",
         "Individual Calibration with Randomized Forecasting",
         "Shengjia Zhao, Tengyu Ma, and Stefano Ermon", 
         icml, 
         "2020", 
         bibtexstring,
         "individualc", 
         'uq',
         'https://github.com/ShengjiaZhao/Individual-Calibration');


addpaper("https://arxiv.org/abs/1910.04284",
         "Improved Sample Complexities for Deep Networks and Robust Classification via an All-Layer Margin",
         "Colin Wei, Tengyu Ma", 
         iclr, 
         "2020", 
         '@inproceedings{wei2019improved, <br> title={Improved sample complexities for deep neural networks and robust classification via an all-layer margin}, <br> author={Wei, Colin and Ma, Tengyu}, <br> booktitle={International Conference on Learning Representations}, <br> year={2019} <br> }',
         "all-layer", 
         'generalization',
         'https://github.com/cwein3/all-layer-margin-opt');

addpaper("https://arxiv.org/abs/2002.11361",
         "Understanding Self-Training for Gradual Domain Adaptation",
         "Ananya Kumar, Tengyu Ma, Percy Liang", 
         icml, 
         "2020", 
         '@inproceedings{kumar2020gradual, <br> title={Understanding Self-Training for Gradual Domain Adaptation}, <br> author={Kumar, Ananya and Ma, Tengyu and Liang, Percy},<br> booktitle={International Conference on Machine Learning (ICML)}, year={2020}, <br> organization={PMLR} <br> }',
         "gradual", 
         'representation',
         'https://github.com/p-lambda/gradual_domain_adaptation');

addpaper("https://arxiv.org/abs/1907.04595",
         "Towards Explaining the Regularization Effect of Initial Large Learning Rate in Training Neural Networks",
         "Yuanzhi Li&#42, Colin Wei&#42, Tengyu Ma", 
         neurips, 
         "2019", 
         '@inproceedings{li2019towards, <br> title={Towards explaining the regularization effect of initial large learning rate in training neural networks}, <br> author={Li, Yuanzhi and Wei, Colin and Ma, Tengyu}, <br> booktitle={Advances in Neural Information Processing Systems}, <br> pages={11674--11685}, <br> year={2019} <br> }',
         "largeLR", 
         'generalization', 
         'https://github.com/cwein3/large-lr-code');


addpaper("https://arxiv.org/abs/1810.05369",
         "Regularization Matters: Generalization and Optimization of Neural Nets v.s. their Induced Kernel",
         "Colin Wei, Jason D. Lee, Qiang Liu, Tengyu Ma", 
         neurips, 
         "2019, <i>spotlight</i>", 
         '@inproceedings{wei2019regularization, <br> title={Regularization matters: Generalization and optimization of neural nets vs their induced kernel}, <br> author={Wei, Colin and Lee, Jason D and Liu, Qiang and Ma, Tengyu}, <br> booktitle={Advances in Neural Information Processing Systems}, <br> pages={9712--9724}, <br> year={2019} <br> }',
         "regmatters", 
         'generalization');

bibtexstring=`@inproceedings{li2020learning,
	title={Learning over-parametrized two-layer neural networks beyond ntk},
	author={Li, Yuanzhi and Ma, Tengyu and Zhang, Hongyang R},
	booktitle={Conference on Learning Theory},
	pages={2613--2682},
	year={2020},
	organization={PMLR}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/2007.04596",
         "Learning Over-Parametrized Two-Layer ReLU Neural Networks beyond NTK",
         "Yuanzhi Li, Tengyu Ma, Hongyang R. Zhang", 
         colt, 
         "2020", 
         bibtexstring,
         "Two-Layerrelu", 
         'opt');

bibtexstring = '@inproceedings{<br>\
  luo2020learning,<br>\
  title={Learning Self-Correctable Policies and Value Functions from Demonstrations with Negative Sampling},<br>\
  author={Yuping Luo and Huazhe Xu and Tengyu Ma},<br>\
  booktitle={International Conference on Learning Representations},<br>\
  year={2020},<br>\
}'

addpaper("https://arxiv.org/abs/1907.05634",
         "Learning Self-Correctable Policies and Value Functions from Demonstrations with Negative Sampling",
         "Yuping Luo, Huazhe Xu, Tengyu Ma", 
         iclr, 
         "2020", 
         bibtexstring,
         "vins", 
         'RL');


addpaper("https://arxiv.org/abs/1906.07413",
         "Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss",
         "Kaidi Cao, Colin Wei, Adrien Gaidon, Nikos Arechiga, Tengyu Ma", 
         neurips, 
         "2019", 
         '@inproceedings{cao2019learning,  <br> title={Learning imbalanced datasets with label-distribution-aware margin loss},  <br> author={Cao, Kaidi and Wei, Colin and Gaidon, Adrien and Arechiga, Nikos and Ma, Tengyu},  <br> booktitle={Advances in Neural Information Processing Systems},  <br> pages={1567--1578},  <br> year={2019} <br> }',
         "imb", 
         'representation',
         'https://github.com/kaidic/LDAM-DRW');



addpaper("https://arxiv.org/abs/1905.03684",
         "Data-dependent Sample Complexity of Deep Neural Networks via Lipschitz Augmentation",
         "Colin Wei,  Tengyu Ma", 
         neurips, 
         "2019 (<i>spotlight</i>)", 
         '@inproceedings{wei2019data, <br> title={Data-dependent sample complexity of deep neural networks via lipschitz augmentation}, <br> author={Wei, Colin and Ma, Tengyu}, <br> booktitle={Advances in Neural Information Processing Systems}, <br> pages={9725--9736}, <br> year={2019} <br> }',
         "Lipschitz_aug", 
         'generalization',
         'https://github.com/cwein3/jacobian-reg');


addpaper("https://arxiv.org/abs/1905.046544",
         "On the Performance of Thompson Sampling on Logistic Bandits",
         "Shi Dong, Tengyu Ma, and Benjamin Van Roy", 
         colt, 
         "2019", 
         '@inproceedings{dong2019performance,<br> title={On the Performance of Thompson Sampling on Logistic Bandits},<br> author={Dong, Shi and Ma, Tengyu and Van Roy, Benjamin},<br> booktitle={Conference on Learning Theory},<br> pages={1158--1160},<br> year={2019}<br>}',
         "tslogistics", 
         'RL');


addpaper("https://arxiv.org/abs/1909.10155",
         "Verified Uncertainty Calibration",
         "Ananya Kumar, Percy Liang, Tengyu Ma", 
         neurips, 
         "2019 (<i>spotlight</i>)", 
         '@inproceedings{{kumar2019calibration, <br> title={Verified Uncertainty Calibration}, <br> author={Kumar, Ananya and Liang, Percy and Ma, Tengyu},<br> booktitle={Advances in Neural Information Processing Systems (NeurIPS)}, <br> year={2019}, pages={3792--3803}, <br> organization={PMLR} <br> }',
         "verified_calibration", 
         'uq',
         'https://github.com/p-lambda/verified_calibration');


bibtexstring = '@inproceedings{<br>\
  luo2019algorithmic,<br>\
  title={Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees},<br>\
  author={Yuping Luo and Huazhe Xu and Yuanzhi Li and Yuandong Tian and Trevor Darrell and Tengyu Ma},<br>\
  booktitle={International Conference on Learning Representations},<br>\
  year={2019},<br>\
  url={https://openreview.net/forum?id=BJe1E2R5KX},<br>\
}'


addpaper("https://arxiv.org/abs/1807.03858",
         "Algorithmic Framework for Model-based Reinforcement Learning with Theoretical Guarantees",
         "Yuping Luo&#42, Huazhe Xu&#42, Yuanzhi Li, Yuandong Tian, Trevor Darrell, Tengyu Ma", 
         iclr, 
         "2019", 
         bibtexstring,
         "slbo", 
         'RL');

bibtexstring=`@inproceedings{zhang2018fixup,
  title={Fixup Initialization: Residual Learning Without Normalization},
  author={Zhang, Hongyi and Dauphin, Yann N and Ma, Tengyu},
  booktitle={International Conference on Learning Representations},
  year={2018}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/1901.09321",
         "Fixup Initialization: Residual Learning Without Normalization",
         "Hongyi Zhang, Yann N. Dauphin, Tengyu Ma",
         neurips, 
         "2019", 
         bibtexstring,
         "fixup", 
         'opt');


bibtexstring=`@inproceedings{bai2018approximability,
  title={Approximability of Discriminators Implies Diversity in GANs},
  author={Bai, Yu and Ma, Tengyu and Risteski, Andrej},
  booktitle={International Conference on Learning Representations},
  year={2018}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/1806.10586",
         "Approximability of Discriminators Implies Diversity in GANs",
         "Yu Bai, Tengyu Ma, Andrej Risteski", 
         iclr, 
         "2019", 
         bibtexstring,
         "approxgans", 
         'otherml');



addpaper("https://arxiv.org/abs/1712.09203",
         "Algorithmic Regularization in Over-parameterized Matrix Sensing and Neural Networks with Quadratic Activations",
         "Yuanzhi Li, Tengyu Ma, and Hongyang Zhang", 
         colt, 
         "2018 (<b>Best Paper Award</b>)", 
         '@inproceedings{li2018algorithmic, <br> title={Algorithmic regularization in over-parameterized matrix sensing and neural networks with quadratic activations}, <br> author={Li, Yuanzhi and Ma, Tengyu and Zhang, Hongyang},<br> booktitle={Conference On Learning Theory}, pages={2--47}, <br> year={2018}, <br> organization={PMLR} <br> }',
         "smallint", 
         'generalization');


bibtexstring=`@article{arora2018linear,
  title={Linear algebraic structure of word senses, with applications to polysemy},
  author={Arora, Sanjeev and Li, Yuanzhi and Liang, Yingyu and Ma, Tengyu and Risteski, Andrej},
  journal={Transactions of the Association for Computational Linguistics},
  volume={6},
  pages={483--495},
  year={2018},
  publisher={MIT Press}
}`.replace(/\n/g, '<br>')

addpaper("http://arxiv.org/abs/1601.03764",
         "Linear Algebraic Structure of Word Senses, with Applications to Polysemy",
         "Sanjeev Arora, Yuanzhi Li, Yingyu Liang, Tengyu Ma, and Andrej Risteski", 
         tacl, 
         "2019", 
         bibtexstring,
         "polysemy", 
         'representation');


bibtexstring=`@inproceedings{khodak2018carte,
  title={A La Carte Embedding: Cheap but Effective Induction of Semantic Feature Vectors},
  author={Khodak, Mikhail and Saunshi, Nikunj and Liang, Yingyu and Ma, Tengyu and Stewart, Brandon M and Arora, Sanjeev},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={12--22},
  year={2018}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/1805.05388",
         "A La Carte Embedding: Cheap but Effective Induction of Semantic Feature Vectors",
         "Mikhail Khodak, Nikunj Saunshi, Yingyu Liang, Tengyu Ma, Brandon Stewart, Sanjeev Arora", 
         acl, 
         "2018", 
         bibtexstring,
         "alacarte", 
         'representation');


bibtexstring=`@article{hardt2018gradient,
  title={Gradient descent learns linear dynamical systems},
  author={Hardt, Moritz and Ma, Tengyu and Recht, Benjamin},
  journal={The Journal of Machine Learning Research},
  volume={19},
  number={1},
  pages={1025--1068},
  year={2018},
  publisher={JMLR. org}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/1609.05191",
         "Gradient Descent Learns Linear Dynamical Systems",
         "Moritz Hardt, Tengyu Ma, and Benjamin Recht", 
         jmlr+',', 
         "19(29):1−44, 2018", 
         bibtexstring,
         "lineardynamicalsystems", 
         'opt');

bibtexstring=`@inproceedings{ge2018learning,
  title={Learning One-hidden-layer Neural Networks with Landscape Design},
  author={Ge, Rong and Lee, Jason D and Ma, Tengyu},
  booktitle={International Conference on Learning Representations},
  year={2018}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/1711.00501",
         "Learning One-hidden-layer Neural Networks with Landscape Design",
         "Rong Ge, Jason D. Lee, and Tengyu Ma", 
         iclr, 
         "2018", 
         bibtexstring,
         "Landscape", 
         'opt');



bibtexstring=`@inproceedings{ge2017optimization,
  title={On the optimization landscape of tensor decompositions},
  author={Ge, Rong and Ma, Tengyu},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3653--3663},
  year={2017}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/1706.05598",
         "On the Optimization Landscape of Tensor decompositions",
         "Rong Ge and Tengyu Ma", 
         neurips, 
         "2017 (<b>oral</b>). Best paper in the NIPS 2016 workshop on nonconvex optimization for ML. Mathematical Programming 2020", 
         bibtexstring,
         "tensorlandscape", 
         'opt');



bibtexstring=`@inproceedings{arora2017generalization,
  title={Generalization and equilibrium in generative adversarial nets (GANs)},
  author={Arora, Sanjeev and Ge, Rong and Liang, Yingyu and Ma, Tengyu and Zhang, Yi},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={224--232},
  year={2017}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/1703.00573",
         "Generalization and Equilibrium in Generative Adversarial Nets (GANs)",
         "Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi Zhang", 
         icml, 
         "2017", 
         bibtexstring,
         "gansgen", 
         'otherml');


bibtexstring=`@article{arora2015latent,
  title={A latent variable model approach to PMI-based word embeddings},
  author={Arora, Sanjeev and Li, Yuanzhi and Liang, Yingyu and Ma, Tengyu and Risteski, Andrej},
  journal={Transactions of the Association for Computational Linguistics},
  year={2016}
}`.replace(/\n/g, '<br>')

addpaper("http://arxiv.org/abs/1502.03520",
         "RAND-WALK: A Latent Variable Model Approach to Word Embeddings",
         "Sanjeev Arora, Yuanzhi Li, Yingyu Liang, Tengyu Ma, and Andrej Risteski", 
         tacl + ',', 
         "4:385-399, 2016", 
         bibtexstring,
         "randomwalk", 
         'representation');


bibtexstring=`@article{hardt2016identity,
  title={Identity matters in deep learning},
  author={Hardt, Moritz and Ma, Tengyu},
  journal={International Conference on Learning Representations},
  year={2017}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/1611.04231",
         "Identity Matters in Deep Learning",
         "Moritz Hardt and Tengyu Ma", 
         iclr, 
         "2017", 
         bibtexstring,
         "Identity", 
         'opt');



bibtexstring=`@article{arora2016simple,
  title={A simple but tough-to-beat baseline for sentence embeddings},
  author={Arora, Sanjeev and Liang, Yingyu and Ma, Tengyu},
  year={2016},
  journal={International Conference on Learning Representations},
}`.replace(/\n/g, '<br>')

addpaper("https://openreview.net/forum?id=SyK00v5xx",
         "A Simple but Tough-to-Beat Baseline for Sentence Embeddings",
         "Sanjeev Arora, Yingyu Liang, and Tengyu Ma", 
         iclr, 
         "2017", 
         bibtexstring,
         "sentence", 
         'representation');

bibtexstring=`@article{lee2017distributed,
  title={Distributed stochastic variance reduced gradient methods by sampling extra data with replacement},
  author={Lee, Jason D and Lin, Qihang and Ma, Tengyu and Yang, Tianbao},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={4404--4446},
  year={2017},
  publisher={JMLR. org}
}`.replace(/\n/g, '<br>')

addpaper("http://arxiv.org/abs/1507.07595",
         "Distributed Stochastic Variance Reduced Gradient Methods by Sampling Extra Data with Replacement",
         "Jason Lee, Qihang Lin, Tengyu Ma, Tianbao Yang", 
         jmlr+',', 
         "18(122):1−43, 2017", 
         bibtexstring,
         "dsvrg", 
         'distml');



bibtexstring=`
@article{chen2019optimal,
  title={Optimal design of process flexibility for general production systems},
  author={Chen, Xi and Ma, Tengyu and Zhang, Jiawei and Zhou, Yuan},
  journal={Operations Research},
  volume={67},
  number={2},
  pages={516--531},
  year={2019},
  publisher={INFORMS}
}`.replace(/\n/g, '<br>')

addpaper("https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2857656",
         "Optimal Design of Process Flexility for General Production Systems",
         "Xi Chen, Tengyu Ma, Jiawei Zhang, Yuan Zhou", 
         "Operations research", 
         "2018", 
         bibtexstring,
         "prodctioin-system", 
         'others');




bibtexstring=`@Article{	  agarwal2017finding,
  title		= {Finding approximate local minima for nonconvex
		  optimization in linear time},
  author	= {Agarwal, Naman and Allen-Zhu, Zeyuan and Bullins, Brian
		  and Hazan, Elad and Ma, Tengyu},
  journal	= {ACM Symposium on Theory of Computing (STOC)},
  year		= {2017}
}
`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/1611.01146",
         "Finding Approximate Local Minima for Nonconvex Optimization in Linear Time",
         "Naman Agarwal, Zeyuan Allen-Zhu, Brian Bullins, Elad Hazan, and Tengyu Ma", 
         stoc, 
         "2017", 
         bibtexstring,
         "localmin", 
         'opt');



bibtexstring=`@inproceedings{arora2017provable,
  title={Provable learning of noisy-or networks},
  author={Arora, Sanjeev and Ge, Rong and Ma, Tengyu and Risteski, Andrej},
  booktitle={Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing},
  pages={1057--1066},
  year={2017}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/1612.08795",
         "Provable learning of Noisy-or Networks",
         "Sanjeev Arora, Rong Ge, Tengyu Ma, and Andrej Risteski", 
         stoc, 
         "2017", 
         bibtexstring,
         "noisyor", 
         'otherml');



bibtexstring=`@inproceedings{ge2016matrix,
  title={Matrix completion has no spurious local minimum},
  author={Ge, Rong and Lee, Jason D and Ma, Tengyu},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2973--2981},
  year={2016}
}`.replace(/\n/g, '<br>')
addpaper("http://arxiv.org/abs/1605.07272",
         "Matrix Completion has No Spurious Local Minimum",
         "Rong Ge and Jason D. Lee and Tengyu Ma", 
         neurips, 
         "2016 (<b>best student paper award</b>)", 
         bibtexstring,
         "matrixcompletion", 
         'opt');



bibtexstring=`@inproceedings{hazan2016non,
  title={A non-generative framework and convex relaxations for unsupervised learning},
  author={Hazan, Elad and Ma, Tengyu},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3306--3314},
  year={2016}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/1610.01132",
         "A Non-generative Framework and Convex Relaxations for Unsupervised Learning",
         "Elad Hazan and Tengyu Ma", 
         neurips, 
         "2016", 
         bibtexstring,
         "Non-generative", 
         'otherml');

bibtexstring=`@inproceedings{ma2016polynomial,
  title={Polynomial-time tensor decompositions with sum-of-squares},
  author={Ma, Tengyu and Shi, Jonathan and Steurer, David},
  booktitle={2016 IEEE 57th Annual Symposium on Foundations of Computer Science (FOCS)},
  pages={438--446},
  year={2016},
  organization={IEEE}
}`.replace(/\n/g, '<br>')


addpaper("https://arxiv.org/abs/1610.01980",
         "Polynomial-time Tensor Decompositions with Sum-of-squares",
         "Tengyu Ma, Jonathan Shi, and David Steurer", 
         stoc, 
         "2017", 
         bibtexstring,
         "sos", 
         'otherml');


bibtexstring=`@inproceedings{arora2016provable,
  title={Provable algorithms for inference in topic models},
  author={Arora, Sanjeev and Ge, Rong and Koehler, Frederic and Ma, Tengyu and Moitra, Ankur},
  booktitle={International Conference on Machine Learning},
  pages={2859--2867},
  year={2016}
}`.replace(/\n/g, '<br>')

addpaper("https://arxiv.org/abs/1605.08491",
         "Provable Algorithms for Inference in Topic Models",
         "Sanjeev Arora, Rong Ge, Frederic Koehler, Tengyu Ma, and Ankur Moitra", 
         icml, 
         "2016", 
         bibtexstring,
         "topic", 
         'otherml');

bibtexstring=`@inproceedings{braverman2016communication,
  title={Communication lower bounds for statistical estimation problems via a distributed data processing inequality},
  author={Braverman, Mark and Garg, Ankit and Ma, Tengyu and Nguyen, Huy L and Woodruff, David P},
  booktitle={Proceedings of the forty-eighth annual ACM symposium on Theory of Computing},
  pages={1011--1020},
  year={2016}
}`.replace(/\n/g, '<br>')

addpaper("http://arxiv.org/abs/1506.07216",
         "Communication Lower Bounds for Statistical Estimation Problems via a Distributed Data Processing Inequality",
         "Mark Braverman, Ankit Garg, Huy L. Nguyen, Tengyu Ma, and David P. Woodruff", 
         stoc, 
         "2016", 
         bibtexstring,
         "sdpi", 
         'distml');

bibtexstring=`@inproceedings{ma2015sum,
  title={Sum-of-squares lower bounds for sparse PCA},
  author={Ma, Tengyu and Wigderson, Avi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1612--1620},
  year={2015}
}`.replace(/\n/g, '<br>')

addpaper("http://arxiv.org/abs/1507.06370",
         "Sum-of-Squares Lower Bounds for Sparse PCA",
         "Tengyu Ma and Avi Wigderson", 
         neurips, 
         "2015", 
         bibtexstring,
         "sparsepca", 
         'others');

bibtexstring=`@article{arora2015deep,
  title={Why are deep nets reversible: A simple theory, with implications for training},
  author={Arora, Sanjeev and Liang, Yingyu and Ma, Tengyu},
  journal={arXiv preprint arXiv:1511.05653},
  year={2015}
}`.replace(/\n/g, '<br>')

addpaper("http://arxiv.org/abs/1511.05653",
         "Why are deep nets reversible: A simple theory, with implications for training",
         "Sanjeev Arora, Yingyu Liang, and Tengyu Ma", 
         'ICLR workshop', 
         "2016", 
         bibtexstring,
         "reversible", 
         'otherml');



bibtexstring=`@inproceedings{ge2015decomposing,
  title={Decomposing Overcomplete 3rd Order Tensors using Sum-of-Squares Algorithms},
  author={Ge, Rong and Ma, Tengyu},
  booktitle={Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques (APPROX/RANDOM 2015)},
  year={2015},
  organization={Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik}
}`.replace(/\n/g, '<br>')

addpaper("http://arxiv.org/abs/1504.05287",
         "Decomposing Overcomplete 3rd Order Tensors using Sum-of-Squares Algorithms",
         "Rong Ge and Tengyu Ma", 
         'RANDOM/APPROX', 
         "2015", 
         bibtexstring,
         "sostensor", 
         'otherml');



addpaper("http://jmlr.org/proceedings/papers/v37/garberb15-supp.pdf",
         "Online Learning of Eigenvectors",
         "Dan Garber and Elad Hazan and Tengyu Ma", 
         icml, 
         "2015", 
         '@inproceedings{garber2015online,<br> title={Online Learning of Eigenvectors.},<br> author={Garber, Dan and Hazan, Elad and Ma, Tengyu}, <br>booktitle={ICML}, <br> pages={560--568}, <br>year={2015}<br>}',
         "eigen", 
         'RL');

bibtexstring=`@article{arora2015simple,
  title={Simple, efficient, and neural algorithms for sparse coding},
  author={Arora, Sanjeev and Ge, Rong and Ma, Tengyu and Moitra, Ankur},
  year={2015},
  publisher={Proceedings of Machine Learning Research}
}`.replace(/\n/g, '<br>')

addpaper("http://arxiv.org/abs/1503.00778",
         "Simple, Efficient, and Neural Algorithms for Sparse Coding",
         "Sanjeev Arora, Rong Ge, Tengyu Ma, and Ankur Moitra", 
         colt, 
         "2015", 
         bibtexstring,
         "sparsecoding", 
         'opt');

bibtexstring=`@inproceedings{garg2014communication,
  title={On communication cost of distributed statistical estimation and dimensionality},
  author={Garg, Ankit and Ma, Tengyu and Nguyen, Huy},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2726--2734},
  year={2014}
}`.replace(/\n/g, '<br>')

addpaper("http://arxiv.org/abs/1405.1665",
         "On the Communication Cost of Distributed Statistical Estimation and Dimensionality",
         "Ankit Garg and Huy Nguy&#7877n and Tengyu Ma", 
         neurips, 
         "2014 (<b>oral</b>)", 
         bibtexstring,
         "distlower", 
         'distml');

bibtexstring=`@inproceedings{arora2014provable,
  title={Provable bounds for learning some deep representations},
  author={Arora, Sanjeev and Bhaskara, Aditya and Ge, Rong and Ma, Tengyu},
  booktitle={International Conference on Machine Learning},
  pages={584--592},
  year={2014}
}`.replace(/\n/g, '<br>')

addpaper("http://arxiv.org/abs/1310.6343",
         "Provable Bounds for Learning Some Deep Representations",
         "Sanjeev Arora, Aditya Bhaskara, Rong Ge, and Tengyuu Ma", 
         icml, 
         "2014", 
         bibtexstring,
         "provabledeep", 
         'otherml');

bibtexstring=`@article{ma2016simulated,
  title={The simulated greedy algorithm for several submodular matroid secretary problems},
  author={Ma, Tengyu and Tang, Bo and Wang, Yajun},
  journal={Theory of Computing Systems},
  volume={58},
  number={4},
  pages={681--706},
  year={2016},
  publisher={Springer}
}`.replace(/\n/g, '<br>')

addpaper("http://arxiv.org/abs/1107.2188",
         "Simulated Greedy Algorithms for Several Submodular Matroid Secretary Problems",
         "Tengyu Ma, Bo Tang, and Yajun Wang", 
         'Theory of Computing Systems', 
         "2016", 
         bibtexstring,
         "matrioid", 
         'others');


addpaper("template",
         "",
         "", 
         neurips, 
         "", 
         bibtexstring,
         "", 
         '');

</script>

<hr>
<p>Last update: 2021/02. Template adapted from <a href="https://www.cs.princeton.edu/~danqic">Danqi Chen</a>'s.</p>

<script src="./Peter Radchenko&#39;s Homepage_files/jquery.min.js"></script>




</div>


<div id="ghostery-tracker-tally" class="ghostery-bottom ghostery-right ghostery-none ghostery-collapsed"><div id="ghostery-box"><div id="ghostery-count" style="background: none; color: rgb(255, 255, 255);">0</div><div id="ghostery-pb-icons-container"><span id="ghostery-breaking-tracker" class="ghostery-pb-tracker" title="Broken Page Trackers" style="background: url(&quot;data:image/svg+xml;base64,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&quot;); opacity: 0.5;"></span><span id="ghostery-slow-tracker" class="ghostery-pb-tracker" title="Slow Trackers" style="background: url(&quot;data:image/svg+xml;base64,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&quot;); opacity: 0.5;"></span><span id="ghostery-non-secure-tracker" class="ghostery-pb-tracker" title="Non-secure Trackers" style="background: url(&quot;data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiIHN0YW5kYWxvbmU9Im5vIj8+DQo8c3ZnIHdpZHRoPSIxOHB4IiBoZWlnaHQ9IjE4cHgiIHZpZXdCb3g9IjAgMCAxOCAxOCIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIj4NCiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDQwICgzMzc2MikgLSBodHRwOi8vd3d3LmJvaGVtaWFuY29kaW5nLmNvbS9za2V0Y2ggLS0+DQogICAgPHRpdGxlPndhcm5pbmc8L3RpdGxlPg0KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPg0KICAgIDxkZWZzPjwvZGVmcz4NCiAgICA8ZyBpZD0iUHVycGxlLUJveCIgc3Ryb2tlPSJub25lIiBzdHJva2Utd2lkdGg9IjEiIGZpbGw9Im5vbmUiIGZpbGwtcnVsZT0iZXZlbm9kZCI+DQogICAgICAgIDxnIHRyYW5zZm9ybT0idHJhbnNsYXRlKC0zNzMuMDAwMDAwLCAtNDUzLjAwMDAwMCkiIGlkPSJ3YXJuaW5nIiBmaWxsPSIjRkVCMDMyIj4NCiAgICAgICAgICAgIDxnIHRyYW5zZm9ybT0idHJhbnNsYXRlKDM3My4wMDAwMDAsIDQ1My4wMDAwMDApIj4NCiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNOSwwLjYzMDQzNDc4MyBDNC4zODQxNDQ5MywwLjYzMDQzNDc4MyAwLjYzMDQzNDc4Myw0LjM4NDE0NDkzIDAuNjMwNDM0NzgzLDkgQzAuNjMwNDM0NzgzLDEzLjYxNTg1NTEgNC4zODQxNDQ5MywxNy4zNjk1NjUyIDksMTcuMzY5NTY1MiBDMTMuNjE1ODU1MSwxNy4zNjk1NjUyIDE3LjM2OTU2NTIsMTMuNjE1ODU1MSAxNy4zNjk1NjUyLDkgQzE3LjM2OTU2NTIsNC4zODQxNDQ5MyAxMy42MTU4NTUxLDAuNjMwNDM0NzgzIDksMC42MzA0MzQ3ODMgWiBNNC42NDI5MjgxMSwxMS43ODk4NTUxIEM1LjI1MDQxMTY1LDExLjc4OTg1NTEgNS43NTY5NTIzNCwxMS4zNjA3NTY3IDUuODc4NzE2OTMsMTAuODgxMzY5NSBDNi4wMDA0ODE1MiwxMS4zNjEyNDM3IDYuNTA3MDIyMjIsMTEuNzIzNzM2OSA3LjExNDM4NCwxMS43MjM3MzY5IEM3LjcyNDE4MTA2LDExLjcyMzczNjkgOC4yMzI2Njk5OSwxMS4zNjUwMTg0IDguMzUxNTEyMjMsMTAuODgyNzA4OSBDOC40NzA5NjMzLDExLjM2NTAxODQgOC45Nzk0NTIyMywxMS43MzY1MjIyIDkuNTg4NzYyMjQsMTEuNzM2NTIyMiBDMTAuMTk0NjYyOCwxMS43MzY1MjIyIDEwLjcwMTIwMzUsMTEuMzk0OTcyNSAxMC44MjM0NTUyLDEwLjkxNjU1OTQgQzEwLjk0NTcwNjgsMTEuMzk0OTcyNSAxMS40NTIyNDc1LDExLjc4OTM2OCAxMi4wNTgyNjk5LDExLjc4OTM2OCBDMTIuMzUzNjcwOCwxMS43ODkzNjggMTIuNjI0NzE4OCwxMS42OTkzODQgMTIuODM5NzU1LDExLjU1OTU5ODIgQzExLjAwOTUxMTUsOC43MTgwOTk3NSAxMi4xNDUzMzE2LDQuMTM3NjgxMTYgMTIuMTQ1MzMxNiw0LjEzNzY4MTE2IEM2Ljk0NjQ3MDYzLDUuMjMxNjE0MjQgNC42NjU4MTk4NSwxMC4xMDAzNzE0IDQuMDU3OTcxMDEsMTEuNjY2MTQyMiBDNC4yMzI5NDY3MywxMS43NDMyMTkyIDQuNDMxNzg4MzEsMTEuNzg5ODU1MSA0LjY0MjkyODExLDExLjc4OTg1NTEgWiIgaWQ9Indhcm5pbmd0cmFja2VycyI+PC9wYXRoPg0KICAgICAgICAgICAgPC9nPg0KICAgICAgICA8L2c+DQogICAgPC9nPg0KPC9zdmc+&quot;); opacity: 0.5;"></span></div><div id="ghostery-title">Looking</div><div id="ghostery-minimize"><span id="ghostery-minimize-icon"></span></div><span id="ghostery-close" style="background: url(&quot;data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiIHN0YW5kYWxvbmU9Im5vIj8+DQo8c3ZnIHdpZHRoPSIxNXB4IiBoZWlnaHQ9IjE1cHgiIHZpZXdCb3g9IjAgMCAxNSAxNSIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIj4NCiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDMuNy4yICgyODI3NikgLSBodHRwOi8vd3d3LmJvaGVtaWFuY29kaW5nLmNvbS9za2V0Y2ggLS0+DQogICAgPHRpdGxlPmNvbGxhcHNlIGNvcHkgMjwvdGl0bGU+DQogICAgPGRlc2M+Q3JlYXRlZCB3aXRoIFNrZXRjaC48L2Rlc2M+DQogICAgPGRlZnM+PC9kZWZzPg0KICAgIDxnIGlkPSJQdXJwbGUtQm94IiBzdHJva2U9Im5vbmUiIHN0cm9rZS13aWR0aD0iMSIgZmlsbD0ibm9uZSIgZmlsbC1ydWxlPSJldmVub2RkIj4NCiAgICAgICAgPGcgaWQ9ImNvbGxhcHNlLWNvcHktMiI+DQogICAgICAgICAgICA8Y2lyY2xlIGlkPSJPdmFsLTMxNSIgZmlsbC1vcGFjaXR5PSIwLjI3MDE1Mzk4NiIgZmlsbD0iI0Q4RDhEOCIgY3g9IjcuNSIgY3k9IjcuNSIgcj0iNy41Ij48L2NpcmNsZT4NCiAgICAgICAgICAgIDxwYXRoIGQ9Ik00LjM2LDQuMzYgTDEwLjU3NDU2MzQsMTAuNTc0NTYzNCIgaWQ9IkxpbmUiIHN0cm9rZT0iI0ZGRkZGRiIgc3Ryb2tlLWxpbmVjYXA9InNxdWFyZSI+PC9wYXRoPg0KICAgICAgICAgICAgPHBhdGggZD0iTTQuMzYsNC4zNiBMMTAuNTc0NTYzNCwxMC41NzQ1NjM0IiBpZD0iTGluZS1Db3B5IiBzdHJva2U9IiNGRkZGRkYiIHN0cm9rZS1saW5lY2FwPSJzcXVhcmUiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDcuNjAwMDAwLCA3LjYwMDAwMCkgc2NhbGUoLTEsIDEpIHRyYW5zbGF0ZSgtNy42MDAwMDAsIC03LjYwMDAwMCkgIj48L3BhdGg+DQogICAgICAgIDwvZz4NCiAgICA8L2c+DQo8L3N2Zz4=&quot;);"></span></div><div id="ghostery-pb-background"><div id="ghostery-trackerList"></div></div></div></body></html>